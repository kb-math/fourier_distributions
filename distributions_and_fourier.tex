\documentclass[twoside, a4paper, 10pt]{amsart}
\title[ ]{Notes on Distributions and their Fourier Transforms}
%\usepackage{amsaddr}
%\email{Kamil.Bulinski@minetec.com.au}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{verbatim}
\usepackage{amsmath, amssymb}
\usepackage{tikz}
\usetikzlibrary{matrix, arrows}
\usepackage{listings}
\usepackage{color}
\usepackage{listings}
\usepackage[all]{xy}
\usepackage[pdftex,colorlinks,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage[margin=3cm]{geometry}
\usepackage{bigints}
\usepackage{dsfont}
\setlength{\textwidth}{6.5in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}
\linespread{1.3}

\begin{document}
\maketitle
\raggedbottom


%% Mathcal large
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cZ}{\mathcal{Z}}
%% Mathbb large
\newcommand{\bA}{\mathbb{A}}
\newcommand{\bB}{\mathbb{B}}
\newcommand{\bC}{\mathbb{C}}
\newcommand{\bD}{\mathbb{D}}
\newcommand{\bE}{\mathbb{E}}
\newcommand{\bF}{\mathbb{F}}
\newcommand{\bG}{\mathbb{G}}
\newcommand{\bH}{\mathbb{H}}
\newcommand{\bI}{\mathbb{I}}
\newcommand{\bJ}{\mathbb{J}}
\newcommand{\bK}{\mathbb{K}}
\newcommand{\bL}{\mathbb{L}}
\newcommand{\bM}{\mathbb{M}}
\newcommand{\bN}{\mathbb{N}}
\newcommand{\bO}{\mathbb{O}}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\bQ}{\mathbb{Q}}
\newcommand{\bR}{\mathbb{R}}
\newcommand{\bS}{\mathbb{S}}
\newcommand{\bT}{\mathbb{T}}
\newcommand{\bU}{\mathbb{U}}
\newcommand{\bV}{\mathbb{V}}
\newcommand{\bW}{\mathbb{W}}
\newcommand{\bX}{\mathbb{X}}
\newcommand{\bY}{\mathbb{Y}}
\newcommand{\bZ}{\mathbb{Z}}


\newcounter{dummy} \numberwithin{dummy}{section}

\theoremstyle{definition}
\newtheorem{mydef}[dummy]{Definition}
\newtheorem{prop}[dummy]{Proposition}
\newtheorem{corol}[dummy]{Corollary}
\newtheorem{thm}[dummy]{Theorem}
\newtheorem{lemma}[dummy]{Lemma}
\newtheorem{eg}[dummy]{Example}
\newtheorem{notation}[dummy]{Notation}
\newtheorem{remark}[dummy]{Remark}
\newtheorem{claim}[dummy]{Claim}
\newtheorem{Exercise}[dummy]{Exercise}
\newtheorem{question}[dummy]{Question}

\section{Distributions}

\begin{mydef} Let $U \subset \bR^n$ be an open set. We define $$D(U) = \{ \varphi :\bR^n \to \bC ~|~ \varphi \text{ is smooth, compactly supported and } \operatorname{supp}(\varphi) \subset U  \}$$ to be the set of \textit{test functions} on $U$. Given $\varphi_1,\varphi_2, \ldots \in D(U)$ and $\varphi \in D(U)$, then we say that $\varphi = \lim_{n \to \infty} \varphi_n$ if there exists a compact set $K \subset U$ such that $\varphi$ and all $\varphi_n$ have support inside $K$ and for all $\alpha \in \bZ_{\geq 0}^n$ we have that $$\partial^{\alpha} \varphi_n \to \partial^{\alpha} \varphi \text{ uniformly on K.}$$ 

\end{mydef}

\begin{eg} Let $h:\bR \to \bC$ be the map $h(x) = \mathds{1}_{(0,\infty)} \exp(-\frac{1}{x})$. This is a smooth map with support $[0, \infty)$. Thus $\varphi:\bR \to \bC$ given by $\varphi(x) = h(x)h(1-x)$ is a smooth map with support $[0,1]$. Thus $\varphi \in D((-\epsilon, 1 + \epsilon))$ for all $\epsilon >0$ (but not for $\epsilon = 0$). Now let $\phi_t \in D(\bR)$ be given by $\phi_t(x) = \phi(x+t)$, then clearly $\lim_{n \to \infty} \phi_{1/n} \phi$ in $D(\bR)$ but the sequence $\phi_n$, $n \in \bZ$, does not converge (because the union of the supports is unbounded, hence not compact).
\end{eg}

Note that $D(U)$ is closed under partial differentiation, and partial differentiation is continuous (preserves limits).

\begin{mydef} A \textit{distribution} on $U \subset \bR^n$ is a linear functional $f:D(U) \to \bC$ that is \textit{continuous} in the sense that if $\phi_1, \phi_2,\ldots \in D(U)$ converge to $\phi \in D(U)$ then $f(\phi_1), f(\phi_1), \ldots$ converges to $f(\phi)$. We let $D'(U)$ denote the space of distributions on $U$. 

\end{mydef}

\begin{eg} Any measure $\mu$ on $\bR^n$ that is finite on compact sets is a distribution in $D(\bR^n)$, e.g., $\phi \mapsto \int \phi d\mu$. Consider the distribution $\delta' \in D'(\bR)$ given by $\delta'(\phi) = -\phi'(0)$. This distribution cannot arise from a measure as can be seen as follows. Choose $\phi_j \in D(\bR)$ supported on $[-1,1]$ such that $\| \phi_j \|_{\infty} \to 0$ but $\phi_j'(0) = 1$, then if $\delta'$ coincides with a measure $\mu$, then we have $-1 = \delta'(\phi_j) = \int \phi_j d\mu \to 0 $, a contradiction.

\end{eg}

The following definition describes why we called the example above $\delta'$.

\begin{mydef} Let $f \in D'(U)$ where $U \subset \bR^n$. Let $\partial_j \phi$ denote the $j$-th partial derivative of a smooth map $\phi$. We can define $\partial_j f \in D'(U)$ by $$\partial_j f (\phi) = - f(\partial_j \phi) \quad \text{ for all } \phi \in D(U).$$ 

\end{mydef}

We now explain the minus sign in the definition.

\begin{prop} Let $f$ be a continuously differentiable function on $\bR^n$ (not necessarily compactly supported). This defines a distribution $\mu_f$ on $\bR^n$ via $\mu_f (\phi) = \int \phi(x) f(x) d^n x$ where $d^n x$ is the lebesgue measure on $\bR^n$. Then $$\partial_j \mu_f = \mu_{\partial_j f}.$$

\end{prop}

\begin{proof} For convenience, suppose $j = n$. Then for any $\phi \in D(U)$ we have 

$$ \mu_{\partial_n f} (\phi) = \int \partial_n f(x) \phi (x) d^n x $$

Now by Fubini's theorem (the integrand has compact support) we can write this integral as $$ \int \left(\int_{-R}^{R} \partial_n f(x_1, \ldots, x_{n-1}, t) \phi (x_1, \ldots, x_{n-1}, t)  dt \right) d^{n-1}(x_1, \ldots, x_{n-1})$$ where $R > 0$ is chosen large enough so that $\phi = 0$ outside of $[-R,R]^n$. Finally, we apply integration by parts to the inner integral and use $\phi(x_1, \ldots, x_{n-1}, \pm R) = 0$ to get that this integral is $$\int \left(\int_{-R}^{R} - f(x_1, \ldots, x_{n-1}, t) \partial_n \phi (x_1, \ldots, x_{n-1}, t)  dt \right) d^{n-1}(x_1, \ldots, x_{n-1})$$ which equals $- \int f(x) \partial_n \phi(x) d^n x$ since $\partial_n \phi = 0$ outside of $[-R,R]^n$.  But this is precisely $-\mu_f(\partial_n) = \partial_n \mu_f$. \end{proof}

Thus we have extended the notion of differentiation to distributions, which include also non-differentiable but locally integrable functions via the embedding $f \mapsto \mu_f$ in the proposition above. We now identify $\mu_f$ and $f$ as is standard practice. 

\begin{eg} Let $H(x) = \mathds{1}_{[0, \infty)} (x)$. Then $H:\bR \to \bR$ is discontinuous at $0$ thus not differentiable in the classical. Yet it has a distribution derivative as follows $H' = \delta$ where $\delta(\phi) = \phi(0)$ is the Dirac delta distribution (which is the probability measure supported at a single point $0$). To see this note that for any smooth $\phi \in D(\bR)$ supported on $[-R,R]$ we have that $$-\int H(x) \phi'(x) = -\int_0^R \phi'(x) dx = -\phi(R) + \phi(0) = \phi(0) = \delta(\phi).  $$

\end{eg}

\begin{eg} Consider a ball that bounces off a wall. Its position can be modelled as $x(t) = t$ for $t<0$ and $x(t) = -t$ for $t \geq 0$ (the wall is located at $x=0$ and it hits it at $t = 0$). Its velocity is $x'(t) = 1$ for $t<0$ and $x'(t) = -1$ for $t>0$ and $x'(0)$ is undefined. What is its acceleration? It is $0$ for all $t \neq 0$, but what is it at $t = 0$? As a distribution the acceleration $x''(t)$ is $2\delta$, which makes sense as all the impact happens at $t=0$. Of course, in real life maybe $x''(t)$ is continuous and the impact happens on some very small time scale $[-\epsilon, \epsilon]$ as the ball is squashed and unsquashed, but nonetheless $\int_{-\epsilon}^{\epsilon} x''(t) dt = 2$ still holds. 

\end{eg}

\begin{mydef}(Convergence of Distributions) We say that a sequence of distributions $f_1,f_2, \ldots \in D'(U)$ converges to $f \in D'(U)$ (in $D'(U)$) if $f_i(\varphi) \to f(\varphi)$ for all $\varphi \in D(U)$

\end{mydef}

\begin{eg} Let $f:\bR \to \bC$ be an integrable function with $\int_{-\infty}^{\infty} f(x) dx = 1$. Let $f_n(x) = n f(nx)$. Thus if $\varphi \in D(\bR)$ then by making the substibution $u = nx$ we get $$\int_{\bR} f_n(x) \varphi(x) dx = \int_{\bR} \frac{du}{dx} f(nx) \varphi(x) dx = \int_{\bR} f(u) \varphi(\frac{u}{n}) du \to \varphi(0) \quad \text{as } n \to \infty$$ where we used the dominated convergence theorem (the integrand is bounded by the integrable function $\| \varphi \|_{\infty} f$ and converges to $f(u)\varphi(0)$ pointwise).Thus $f_n \to \delta$ in $D'(\bR)$.

\end{eg}

\begin{lemma} Suppose that $\phi_n, \psi_n, \phi, \psi:U \to \bR$ are smooth functions, where $U \subset \bR^d$ is open, such that for some compact $K \subset U$ and for all $\alpha \in \bZ^d_{\geq 0}$ we have that $\partial^{\alpha} \phi_n \to \partial^{\alpha}\phi$ and $\partial^{\alpha} \psi_n \to \partial^{\alpha}\psi$ uniformly on $K$. Then for all $\alpha$, we have that $\partial^{\alpha} (\phi_n \psi_n) \to \partial^{\alpha} (\phi_n \psi_n)$ uniformly on $K$.

\end{lemma}

\begin{proof} First we note that $$|\phi_n \psi_n - \phi \psi| = |\phi_n (\psi_n - \psi) + \psi (\phi_n - \phi)| \leq |\phi_n||\psi_n - \phi_n| + |\psi||\phi_n - \phi|$$ converges to $0$ uniformly on $K$. We now prove by induction on $k$ that all order $n$ derivatives of $\phi_n \psi_n$ converge to the corresponding derivatives of $\phi \psi$ (the induction hypothesis is on any such $\phi$, $\psi$ and not just for this specific ones). The base case $k=0$ has now been establishes. Now choose any $1\leq j \leq n$ and use the product rule to see that $$\partial_j (\phi_n \psi_n) = \partial_j(\phi_n) \psi_n + \phi_n (\partial_j \phi_n) \to \partial_j(\phi) \psi + \phi (\partial_j \phi) = \partial_j(\phi \psi)$$ uniformly on $K$ where we applied this $k=0$ case. Now by induction hypothesis for $|\alpha| = k$ we have $\partial_{\alpha} \partial_j(\phi_n) \psi_n \to \partial_{\alpha} \partial_j(\phi) \psi $ uniformly on $K$ and likewise for the second term. Thus $\partial_{\alpha} \partial_j (\phi_n \psi_n) \to \partial_{\alpha} (\phi \psi)$, and this completes the induction step. \end{proof}

\begin{mydef}[Multiplying a distribution by a smooth function] If $f \in D(U)$ is a distributiona and $\psi \in C^{\infty}(U)$ is any smooth function (not necessarily of compact support in $U$) then we can define $\psi f \in D(U)$ by $$\psi f (\phi) = f(\psi \phi).$$ Note that $\psi f$ is indeed a distribution as the above lemma shows that if $\phi_n \to \phi$ in $D(U)$ then $\psi \phi_n \to \psi \phi$ in $D(U)$ as well, and so $\psi f (\phi_n) \to \psi f(\phi)$ by the continuity of $f$.

\end{mydef}
\section{Test functions as a Frechet space}

\begin{mydef} A Frechet space is a topological vector space (addition and scalar multiplcation is continuous, the field is either $\bR$ or $\bC$ which has the usual topology) whose topology comes from an invariant metric $d$ (i.e., $d(v_1+v, v_2+v) = d(v_1, v_2)$ for all $v_1,v2,v \in V$) that is complete.

\end{mydef}

For $K \subset \bR^n$ compact we define the norm $$\| \phi \|_{C^k} = \sup_{x \in K, |\alpha| \leq k} |\partial^{\alpha} \phi| (x).$$ Note that $C_0^k(K)$ is a Banach space and hence a Frechet space with respect to this norm. We define $C_0^{\infty}(K)$ to be the smooth functions with support inside $K$ and for $\phi \in C_0^{\infty}(K)$ we define $$\|\phi\|_{C_0^{\infty}(K)} = \sum_{k=0}^{\infty} 2^{-k} \min\{1, \| \phi \|_{C^k} \} $$ and we note that $d(\phi_1, \phi_2) = \| \phi_1 - \phi_2 \|_{C_0^{\infty}(K)}$ is an invariant metric that is complete. Moreover, a sequence of test functions $\phi_1, \phi_2, \ldots \in C_0^{\infty}(K)$ converge to $\phi \in C_0^{\infty}(K)$ if and only if for all $\alpha \in \bZ_{\geq 0}^n$ we have that $$\partial^{\alpha} \phi_i \to \phi$$ uniformly on $K$. In other words, a sequence of test functions in $D(U)$ converges if they all have support inside the same compact subset $K \subset U$ and they converge in $C_0^{\infty}(K)$ with respect to this metric. This in particular verifies that $C_0^{\infty}(K)$ is a topological vector space with respect to this metric (the continuity of addition and scalar multiplcation inherits from the same properties of the norms $\|\cdot \|_{C_k}$).

\begin{thm}[Theorem 3.8 of \cite{DK}] \label{thm: distributions are lipschitz on compact sets} Let $U \subset \bR^d$ be open. A linear functional $f:D(U) \to \bC$ is a distribution (in $D'(U)$) if and only if for all compact subsets $K \subset U$ there exists $c>0$ and $k \in \bZ_{\geq 0}$ such that

$$ |f(\phi)| \leq c \|\phi\|_{C^k} \quad \text{for all } \phi \in C_0^{\infty}(K).$$

\end{thm}

\begin{proof} Easy to see that any functional satisfying this property is a distribution. To see the converse, suppose that this conditional fails for some compact set $K \subset U$. Then for each positive integer $c = k$ we have $$|f(\phi_k)| > k \|\phi_k\|_{C^k}$$ for some $\phi_k \in C_0^{\infty}(K)$. Let $\psi_k = \frac{1}{|f(\phi_k)|} \phi_k$. Thus $|f(\psi_n)| = 1$ but we have $$|\psi_n|_{C^k} \leq |\psi_n|_{C^n} < \frac{1}{n}$$ for all $n \geq k$ so $\psi_n \to 0$ on $C_0^{\infty}(K)$, which shows that $f$ is not continuous, i.e., not a distribution. \end{proof}

\begin{thm}[Uniform boundedness] Let $V$ be a Frechet space and suppose that $\mathcal{F}$ is a set of continuous linear functions $f:V \to \bC$ such that $\{ f(x) ~|~ f \in \mathcal{F} \}$ is bounded in $\bC$ for all $x \in V$. Then there is an open set $U \subset V$ with $0 \in V$ such that $|f(u)| \leq 1$ for all $f \in \mathcal{F}$ and $u \in U$. \end{thm}


\begin{proof} Let $$U_n = \{ x \in V ~|~ |f(x)| > n \text{ for some } f \in \mathcal{F} \}$$. Now $U_n$ is an open set. For each $x \in V$, we have that there exists $n$ such that $|f(x)| \leq n$ for all $f \in \mathcal{F}$, which means that $x \notin U_n$. Consequently $$\emptyset = \bigcap_{n=1}^{\infty} U_n.$$ Thus not all $U_n$ can be dense by Baire's theorem. As some $U_n$ is dense, we have a non-empty open set $V$ such that $V \cap U_n = \emptyset$. Choosing $v_0 \in V$, we have that if $u \in V-v_0$ then $u = v-v_0$ for some $v \in V$ and so $$|f(u)| = |f(v) - f(v_0)| \leq |f(v)| + |f(v_0)| \leq 2n.$$ Thus we may set $U = \frac{1}{2n}(V-v_0)$, which is open by definition of topological vector space. \end{proof}

\begin{thm}[Lemma 5.4 in \cite{DK}, no proof given there] Let $f_j$ be a sequence of distributions in $D'(U)$, where $U \subset \bR^d$ is open such that $f_j(\phi)$ is bounded for all $\phi \in D(U)$. Then for all compact $K \subset U$ there exists a constant $c>0$ and $k \in \bZ_{\geq 0}$ such that $$\|f_j(\phi)\| \leq c \| \phi \|_{C_0^k(K)} \quad \text{ for all } j \in \bN \text{ and } \phi \in C_0^{\infty}(K).$$

\end{thm}

\begin{proof} We apply the uniform boundedness principle above. This implies that there is an open neighbhourhood $\mathcal{U} \subset C_0^{\infty}(K)$ such that $f_j(u) \leq 1$ for all $u \in \mathcal{U}$ and $j \in \bN$. So there exists an $R$ such that if $\| \phi \|_{C_0^{\infty}(K)} < R$ then $f_j(\phi) \leq 1$. Now take $k$ large enough so that $$\sum_{i=k}^{\infty} 2^{-i} < \frac{R}{2}.$$ This means that if $\|\phi \|_{C_0^{k}(K)} < \frac{R}{2}$ then $\| \phi \|_{C_0^k(K)} < R$ and so $f_j(\phi) < 1$. As $\|\cdot \|_{C_0^k(K)}$ is a norm on $C_0^{\infty}(K)$, we have completed the proof with $c= \frac{2}{R}$.  \end{proof}

\begin{thm} Let $U \subset \bR^d$ be an open set and suppose that $f_1,f_2, \ldots \in D(U)$ is a sequence of distributions such that $\lim_{j\to \infty} f_j(\varphi)$ exists in $\bC$ for all $\varphi \in D(U)$. 
\begin{enumerate}
	\item Then there exists a a distribution $f \in D(U)$ such that $$f = \lim_{j \to \infty} f_j.$$
	\item If $\varphi, \varphi_j \in D(U)$ are such that $\lim_{j \to \infty} \varphi_j = \varphi$ then $f_j(\varphi_j)$ converges to $f(\varphi)$.
\end{enumerate}

\end{thm}

\begin{proof} Define $f(\varphi) = \lim_{j \to \infty} f_j(\varphi)$. It remains to show that this defines a distribution (is continuous). Let $K$ be a compact set. Applying the uniform boundedness principle we have a constant $c>0$ and $k \in \bZ_{\geq 0}$ such that $$|f_j(\varphi)| \leq c \| \varphi \|_{C_0^k(K)} \quad \text{ for all } j \in \bN, \varphi \in C_0^{\infty}(K).$$ Thus as $f_j(\varphi) \to f(\varphi)$ we have that $$|f(\varphi)| \leq c \| \varphi \|_{C_0^k(K)} \quad \text{ for all } \varphi \in C_0^{\infty}(K).$$ This implies the continuity of $f$, thus $f \in D(U)$. Now suppose that $\varphi_j \in C_0^{\infty}(K)$ converge to $\varphi \in C_0^{\infty}(K)$. Thus $$|f_j(\varphi_j) - f(\varphi)| \leq |f_j(\varphi_j - \varphi)| + |f_j(\varphi) - f(\varphi)| \leq c\|\varphi_j - \varphi\|_{C^k} +  |f_j(\varphi) - f(\varphi)|$$ and the first term converges to $0$ as $\varphi_j \to \varphi$ while the second converges to $0$ as $f_j \to f$.\end{proof}

\section{Support of a distribution}

If $U \subset V \subset \bR^d$ are open sets, then there is a continuous (preserves limits) inclusion $D(U) \to D(V)$. This induces a restriction map $p_{U,V}:D'(V) \to D'(U)$ where $(p_{U,V}f)(\phi) = f(\phi)$ for $\phi \in D(U) \subset D(V)$ and $f \in D'(U)$. Note that this is continuous (preserves limits of distributions). We also use the notation $f|_U = p_{U,V}f$.

\begin{lemma} Suppose that $U$ is an open set, $f \in D'(U)$ and suppose that for each $x \in U$ there exists an open neighbhourhood $U_x \subset U$ of $x$ such that $p_{U_x, U} f = 0$. Then $f=0$.

\end{lemma}

\begin{proof} We take $\phi \in D(U)$, thus there is a compact set $K$ such that $K \subset u$ and $\phi$ is supported on $K$. Now by compactness, we can find a finite cover of $U_1, \ldots U_n$ of $K$ such that $f$ restricts to $0$ on each $U_i \subset U$. Choose $U_i$ such that the closure of $U_i$ is in $U$. By partition of unity theorem, we may choose $\psi_1, \ldots, \psi_n \in D(U)$ such that $\sum_{i=1}^n \psi_i (x) = 1$ for all $x \in K$ and $\operatorname{supp} \psi_i \subset U_i$. Thus $\phi = \phi \sum_{i} \psi_i$ and so $f(\phi) = \sum_i f(\phi \psi_i) = 0.$ \end{proof}

This lemma shows that if $f|_V = 0$ for all $V \in \mathcal{V}$, where $\mathcal{V}$ is a collection of open sets, then setting $V_{\max} = \cup_{V \in \mathcal{V}} V$ we have that $f|_{V_{\max}} = 0$. Thus the following definition is well defined.

\begin{mydef} If $U \subset \bR^d$ is open and $f \in D'(X)$ we define the support of $f$, denoted by $\operatorname{supp} f$, to the smallest closed set such that $f|V = 0$ where $V = X \setminus \operatorname{supp} f$.

\end{mydef}

\begin{eg} Consider the distribution $f \in D'(\bR_{>0})$ given by $$f(\phi) = \int_0^{\infty} e^{1/x^2} \phi(x) dt.$$ It is indeed a distribution since $e^{-1/x^2}$ is integrable on each compact subset of $\bR_{>0}$, but on any other compact subset containing $0$. This distribution is not the restriction of any distribution $g \in D(\bR)$. To see this, suppose that it was. Now let $\phi_n = \phi(x+\frac{1}{n})$ where $\phi:\bR \to [0,1]$ is smooth and has support in $[0,1]$ and $\phi(x) > e^{-1/x}$ on $(0,\frac{1}{2})$. Thus $$g(\phi) = \lim_{n \to \infty} g(\phi_n) = \lim_{n \to \infty} f(\phi_n) = \infty,$$ a contradiction (distributions have finite values in $\bC$).

\end{eg}

We justify the partition of unity used above.

\begin{prop} Let $B(a,r) \subset B(a,r') \subset \bR^d$ are open balls. There is a smooth function $\phi:\bR^d \to [0,1]$ that is $1$ on $B(a,r)$ and $0$ outside $B(a,r')$. 

\end{prop}

\begin{proof}[Proof sketch] We just need to prove this for $d=1$ and then build such a radial function. We already saw that we have a compactly supported $\psi:\bR \to [0,1]$ supported on $[0,\epsilon]$ where $0<\epsilon<\frac{1}{2}$. Now let $\psi_2(x) = \int_{-\infty}^x \psi(t) dt$. We see that $\psi_2(x)$ is constant for $x>\epsilon$ and is zero on $x<0$. Consequently $\psi_3(x) = \psi_2(x) \psi_2(1-x)$ has values in $[0,1]$, is compactly supported and is constant on the interval $(\epsilon, 1 - \epsilon)$. We can now translate and scale $\psi_3$ appropriately. \end{proof}

\begin{prop}[Partition of unity] Let $K \subset \bR^d$ be a compact set and suppose that $U \supset K$ is open. Suppose that $\mathcal{U}$ is a collection of open subsets of $U$ that covers $K$. Then there exist smooth functions $\psi_1, \ldots, \psi_n:\bR^d \to [0,1]$ such that $$\psi := \sum_{i=1}^n \psi_i$$ satisfies that $\psi(x)=1$ for $x \in K$ and $\psi_i$ has support inside some element of $\mathcal{U}$.

\end{prop}

\begin{proof} By compactness, we may find finitely many balls $B(a_1,r_1), \ldots , B(a_n,r_n)$ that cover $K$ such that $B(a_i,2r_i)$ is a subset of some element of $\mathcal{U}$ (and thus $B(a_i, 2r_i)$ are subsets of $U$). Now apply the previous construction to find some smooth $\phi_i:\bR^d \to [0,1]$ that equals $1$ on $B(a_i,r_i)$ and has support inside $B(a_i,2r_i)$. Now let $\psi_1 = \phi_1$ and for $1<i\leq n$ define $\psi_i = \phi_i \prod_{j<i} (1 - \phi_j)$. Observe that $\psi_i$ has support inside the support of $\phi_i$, thus inside some element of $\mathcal{U}$, as required. Moreover, by induction we have that $$\sum_{i=1}^j \psi_i = 1 - \prod_{i=1}^j (1-\phi_i).$$ In particular for $j=n$ this means that by setting $\psi = \sum_{i=1}^n \psi_i$ we have that $\psi(x) = 1$ for $x \in B(a_ i, r_i)$, and thus for all $x \in K$. Moreover, if $\phi(x)=0$ then $\psi_i(x) = 0$ and thus $\psi_i$ has support inside some element of $\mathcal{U}$, as required. \end{proof}

\begin{thm}[Gluding distributions] Suppose that $X \subset \bR^d$ is an open set and suppose that $\mathcal{U}$ is a collection of open subsets of $X$ that cover $X$. Suppose that for each $U \in \mathcal{U}$ there is a distribution $f_U \in D'(U)$ such that these $f_U$ are compatible in the sense that $f_U|_{U \cap V} = f_V|_{U \cap V}$ are the same distributions on $D'(U \cap V)$. Then there is a unique distribution $f \in D'(X)$ such that $f|U = f_U$ for all $U \in \mathcal{U}$.

\end{thm}

\begin{proof} We construct $f$ as follows (show that it is well defined later): For each $\phi \in D(X)$, choose a compact set $K \subset X$ containing the support of $\phi$. Now we may apply Parition of Unity to find open sets $U_1, \ldots, U_n \in \mathcal{U}$ that cover $K$ and $\psi_i:\bR^d \to [0,1]$ with support inside $U_i$ such that $\psi := \sum_{i=1}^n \psi_i$ satisfies that $\psi(x) = 1$ for all $x \in K$. We now define $$f(\phi) = \sum_{i=1}^n f_{U_i}(\phi \psi_i).$$ Note that this shows uniqueness since $\phi = \sum_{i=1}^n \phi \psi_i$ on $\bR^d$.

We now show that $f$ is well defined (does not depend on the choice of $K$ or the choice of the $U_i$ or the choice of $\psi_i$). To see this, suppose that $K'$, $U'_j$ and $\psi'_j$ are such other choices. Then we make a common refinement and show it assigns the same value to our $f(\phi)$ as follows. Let $K'' = K \cap K'$, it clearly contains the support of $\phi$ and is compact. Now the sets $U_i$ and $U_j$ cover $K''$. Thus the sets $V_{i,j} = U_i \cap U_j$ cover $K''$. Moreover, $\psi_{i,j}:=\psi_i \psi'_j:\bR^d \to [0,1]$ has support inside $V_{i,j}$ and $$\sum_{i,j} \psi_{i,j} = \left(\sum_i \psi_i \right) \left( \sum_j \psi'_j \right)$$ and thus equals $1$ on $K''$. So this common refinement is a new partition of unity. But now 

$$\sum_{i,j} f_{U_i}|_{V_{i,j}}(\psi_{i,j}\phi) = \sum_{i,j} f_{U_i}(\psi_{i,j}\phi)  = \sum_i f_{U_i}(\phi\psi_{i}\sum_j \psi'_j) = \sum_i f_{U_i}(\phi \psi_i) $$ 

where we used that $\phi \psi_i \sum_j \psi'_j = \phi_i\psi_i$ since $\sum_j \psi'_j(x) = 1$ for all $x \in K'$ and thus all $x$ in the support of $\phi$. This completes the proof of well definedness since by assumption, $$f_{U_i}|_{V_{i,j}}(\psi_{i,j}\phi) = f_{U_j'}|_{V_{i,j}}(\psi_{i,j}\phi)$$ and so  $$\sum_i f_{U_i}(\phi \psi_i) = \sum_j f_{U'_j}(\phi \psi'_j)$$ by the same calculation as above. Suppose that $\phi, \phi' \in D(X)$. Thus to compute $f(\phi + \phi')$ we may choose a compact set $K \subset U$ that contains the support of $\phi$ and $\phi'$. Now choose $U_1, \ldots, U_n \in \mathcal{U}$ that cover $K$, thus by definition $$f(\phi_1 + \phi_2) = \sum_{i} f_{U_i} (\psi_i (\phi_1 + \phi_2)) = \sum_i f_{U_i}(\psi_i \phi_1) + \sum_i f_{U_i}(\psi_i \phi_2) = f(\phi_1) + f(\phi_2)$$ where the $\psi_i$ are chosen as in the construction. Linearity of $f$ now easily follows. We now show the continuity of $f$. If $\phi_k \to \phi \in D(X)$ then there is a compact set $K \subset X$ containing all their supports. Thus $\psi_i \phi_k \to \psi \phi$ and the continuity of each $f_{U_i}$ gives continuity of $f$. Finally, it remains to show that $f|_{U} = f_{U}$ for all $U \in \mathcal{U}$. Thus suppose that $\phi \in D(U)$ and choose a compact set $K \subset U$ such that $\phi$ has support inside $K$. As $U$ already covers $K$, by definition we have that $$f|_U(\phi) = f(\phi) =  f_U(\psi \phi) = f_U(\phi)$$ for some $\psi:\bR^d \to [0,1]$ smooth that equals $1$ on $K$ and has suppose inside $U$ (so $\phi\psi = \psi$ everywhere). \end{proof}

\section{Distributions with compact supports}

If $X \subset \bR^d$ is an open set, we let $\mathcal{E}(X) = C^{\infty}(X)$ denote the set of all smooth functions on $X$. We have $D(X) \subset \mathcal{E}(X)$ and the inclusion may be strict, for example constant non-zero functions are not in $D(\bR)$ but are in $C(\bR)$.

\begin{mydef} We say that $\phi_j \in \mathcal{E}(X)$ converges to $\phi \in \mathcal{E}(X)$ if for all compact sets $K \subset X$ and $\alpha \in \bZ_{\geq 0}^d$ we have that $$\partial^{\alpha}\phi_j \to \partial^{\alpha}\phi \quad \text{uniformly on } K. $$

\end{mydef}

\begin{eg} In $\mathcal{E}(\bR)$, we have that $f_n(x) = \frac{1}{n}x$ converge to the $0$ function. However the convergence is not uniform on the whole of $\bR$ itself, but is on every bounded (hence every compact) set. If $\phi:\bR \to \bR$ is a smooth compactly supported non-zero function then $\phi \in D(X) \subset \mathcal{E}(X)$ and $\phi_n(x) = \phi(x-n)$ are also in $\mathcal{E}(X)$. Note that $\phi_n \to 0$ in $\mathcal{E}(X)$ but not in $D(X)$ (as there is no compact subset containing all supports of the $\phi_n$). \end{eg}

\begin{mydef} If $X \subset \bR^d$ is open, we let $\mathcal{E}'(X)$ denote the space of linear maps $f:\mathcal{E}(X) \to \bC$ that satisfy the property that if $\phi_j \in \mathcal{E}(X)$ converges to $\phi \in \mathcal{E}(X)$. We say $f_j \in \mathcal{E}'(X)$ converges to $f \in \mathcal{E}'(X)$ if $f_j(\phi) \to f(\phi)$ for all $\phi \in \mathcal{E}(X)$.

\end{mydef}

We now aim to classify $\mathcal{E}'(X)$ and find a natural embedding into $D'(X)$. First observe that given $f \in \mathcal{E}'(X)$, if we restrict this function to $D(X)$, then we get an element of $\mathcal{D}'(X)$. Thus we have a map $$\iota:\mathcal{E}'(X) \to D'(X).$$

\begin{lemma} If $X \subset \bR^d$ is open, then it has an \textit{exhuastion by compact sets}, which we define to be a sequence $K_1 \subset K_2 \subset \ldots$ of compact sets such that $$X = \bigcup_{n=1}^{\infty} K_n$$ and such that any compact sets $K \subset X$ satisfies that $K \subset K_n$ for some $n$.

\end{lemma}

\begin{proof} If $X = \bR^d$, just take a compact ball of radius $n$. Otherwise, let $C = \bR^d \setminus X$. Note that $C$ is closed. Now let $K_n \subset X$ be those points in ball of radius $n$ around $0$ with distance at most $\frac{1}{n}$ to $C$. Clearly $X = \bigcup_{n=1}^{\infty} K_n$ since any point not in $C$ must have positive distance to $C$ as $C$ is closed. Now let $K \subset X$ be any open set. Then $K \cap C = \emptyset$ and it follows that $K$ has positive distance to $C$, as otherwise there is $k_n \in K$ and $c_n \in C$ such that $d(k_n, c_n) \to 0$ and by taking a subsequence we assume $k_n \to k \in K$, thus $d(k, C) = 0$, contradicting the disjointness of $K$ and $C$. It follows that $K \subset K_n$ for large enough $n$ as $K$ is bounded and has positive distance to $C$.

\end{proof}

\begin{lemma}\label{lemma: E' embeds in D'} The map $\iota:\mathcal{E}'(X) \to 'D(X)$ is well defined, continuous (preserves limits) and injective.

\end{lemma}

\begin{proof} To see well defined, observe that $D(X) \subset \mathcal{E}(X)$ this embedding is continuous, i.e., if $\phi_j \to \phi$ in $D(X)$ then their partial derivatives converge uniformly on all compact sets $K$ by definition. Thus if $f \in \mathcal{E}'(X)$ then indeed $f|_{D(X)} \in \mathcal{E}(X)$. Continuity is obvious as the definition is the same. 

Now we show injectivity, thus we wish to show that this linear map $\iota$ has a trivial kernel. Thus suppose that $f \in \mathcal{E}'(X)$ satisfies that $f(\phi) = 0$ for all $\phi \in D(X)$. We must now show that $f(\psi) = 0$ for all $\psi \in \mathcal{E}(X)$. To see this, first write $$X = \bigcup_{n=1}^{\infty} K_n$$ where $K_1 \subset K_2 \subset \ldots$ is an exhuastion by compact subsets of $X$ (as defined in the lemma above). Now by partition of unity theorem, we can find a map $\phi_n:\bR^d \to [0,1]$ with compact support inside $X$ that is equal to $1$ on $K_n$.  Thus $\phi_n \psi \in D(X)$ as it has compact support in $X$. Hence $f(\phi_n \psi) = 0$ by assumption. Now $\phi_n\psi \to \psi$ in $\mathcal{E}(X)$ since for any compact set $K$, we have that $K \subset K_n$ for large enough $n$ and so $\phi_n\psi = \psi$ on $K$. Thus by continuity of $f$, we have that $$f(\phi) = \lim_{n \to \infty} f(\phi_n \psi) = 0,$$ as desired. \end{proof}

The next example shows that this embedding is not surjective.

\begin{eg} Consider the distribution $f \in D'(\bR)$ given by $f(\phi) = \int_{\bR} \phi(x) dx $. We claim that $f \neq \iota g$ for some $g \in \mathcal{E}'(X)$. Again let $\phi_n:\bR \to [0,1]$ be a compactly supported function equal to $1$ on $[-n,n]$. Then $g(\phi_n) = f(\phi_n) > 2n$ does not converge to any value. But $\phi_n$ converges in $\mathcal{E}(X)$ to the constant function $1$ thus $g(\phi_n)$ should converge, a contradiction. 

\end{eg}

\begin{lemma} Let $f \in D'(X)$ be a distribution with support $K$ such that $K \subset X$. Then $f$ extends to an element of $\mathcal{E}'(X)$ (is in the image of the map $\iota$).

\end{lemma}

\begin{proof} Let $\psi \in \mathcal{E}(X)$. Let $\phi \in D(X)$ be an element such that $\phi = 1$ on some open set $U \supset K$ such that $\overline{U} \subset X$ and $\overline{U}$ is compact (exists as $K \subset X$ and we use partition of unity). Now define $g(\psi) = f(\psi \phi)$. We claim that this defines $g \in \mathcal{E}'(X)$. To show that it is well defined, we see that $\psi \phi \in D(X)$ thus $f(\psi \phi)$ makes sense (no need to show independence on $\phi$, just consider it fixed throughout). Continuity of $g$ is clear since if $\psi_n \to \psi$ in $\mathcal{E}(X)$ then their partial derivatives convege uniformly on the support of $\phi$, thus $\psi_n\phi \to \psi_n \phi$ in $D(X)$. Now it remains to show that $g$ agrees with $f$ on $D(X)$. Thus assume $\psi \in D(X)$ already. Now observe that $\psi - \psi\phi = 0$ on $\overline{U}$ and thus $X \in D(U \setminus K)$  and by definition of support, we have that $f|_{X \setminus K} = 0$ and so $f(\psi - \psi \phi) = 0$, thus $g(\psi) = f(\psi)$ as desired.\end{proof}

We now show that the converse is true, i.e., that $\mathcal{E}'(X)$ coincides with those distributions in $\mathcal{D}'(X)$ whose support is a compact subset of $K$.

\begin{thm} A distribution $f \in D'(X)$ is the restriction of some $g \in \mathcal{E}'(X)$ if and only if the support of $f$ is some compact subset $K \subset X$. 

\end{thm}

\begin{proof} Suppose that $g \in \mathcal{E}'(X)$, we wish to show that it has compact support $K$ for some $K \subset X$ as an element $g \in D'(X)$. Suppose that it does not, thus for any compact set $K \subset X$ we have that $g|_{X \setminus K}$ is not the zero distribution on $X \setminus K$. Thus there exists $\phi_K \in D(X \setminus K)$ such that $g(\phi_K) = 1$. Now let $K_1 \subset K_2 \subset \ldots $ be an exhaustion of $X$ by compact sets. Set $\phi_{n} = \phi_{K_n}$.We claim that $\phi_n \to 0$ in $\mathcal{E}(X)$ (not necessarily in $D(X)$ though). To see this, let $K \subset X$ be any compact set. Then $K \subset K_n$ for large enough $n$, but then $\phi_n = 0$ on such $K_n$ as $\phi_n \in D(X \setminus K_n)$. Thus indeed $\phi_n \to 0$ uniformly on each compact set of $K$, thus $1 = g(\phi_n) = f(\phi_n) \to 0$ by continuity of $f$ on $\mathcal{E}(X)$. A contradiction. \end{proof}

\begin{eg} The distribution $f(\phi) = \int_{0}^1 \phi(x) dx $ is a compactly supported distribution on $\bR$, thus it is defined and continuous on all of $C^{\infty}(\bR)$. Note that if $\phi_n(x) = \phi(x+n)$ where $\phi:\bR \to \bR$ is a non-zero compactly supported smooth function, then $\phi_n \to 0$ in $\mathcal{E}(X)$ and indeed $f(\phi_n) \to 0$. However $\phi_n$ does not converge to $0$ in $D(X)$.

\end{eg}

\begin{eg} Consider the distribution on $(0,1)$ given by $$f(\phi) = \int_{0}^1 e^{1/x^2} \phi(x) dx.$$ It is continuous and well defined since $e^{1/x^2}$ is integrable on each compact subset $K$ in $(0,1)$. However, $f \notin \mathcal{E}'((0,1))$ (not the restriction of any element in $\mathcal{E}'((0,1))$). Indeed, it is not supported on any compact subset $K$ of $(0,1)$. This is despite the support being the bounded subset $(0,1)$ that is closed in $(0,1)$ but not in $\bR$. One can directly see that there is not continuous extension of $f$ to $\mathcal{E}((0,1))$ by considering a sequence of elements $\phi_n \in D((0,1))$ that converge monotonically in $\mathcal{E}(X)$ to the constant function $1$ on $(0,1)$ and seeing a lack of convergence ($f(\phi_n)$ diverges to $\infty$).

\end{eg}

\begin{thm} For any open $X \subset \bR^d$, we have that $\mathcal{E}'(X)$ is a dense subset of $D'(X)$.

\end{thm}

\begin{proof} Let $K_1 \subset K_2 \subset \ldots $ be an exhuastion of $X$ be compact subsets. Choose a $\psi_n \in D(X)$ such that $\psi_n = 1$ on $K_n$. Now let $f \in D(X)$ be any distribution and define $f_n = \psi_n f \in D(X)$ by $$f_n(\phi) = f_n(\phi \psi_n).$$ We claim that $f_n \in \mathcal{E}'(X)$ and $f_n \to f$ in $D'(X)$. To justify the first claim, note that for $\phi \in D(U \setminus \operatorname{supp} \psi_n)$ we have that $$f_n(\phi) = f(\psi_n \phi) = f(0) = 0$$ which shows that $f_n$ has support a subset of $\operatorname{supp} f$, thus has compact support. Now for any $\phi \in D(X)$, there is a compact set $K \subset X$ such that $\phi(x) = 0$ for $x \notin K$. Also, for $n$ large enough we have $K \subset K_n$, thus $\phi = \phi \psi_n$ and so $f_n(\phi) = f(\phi)$ for large enough $n$. \end{proof}

\section{Convolution of Functions}

\begin{prop}\label{prop: convolution of L1 is L1} Let $f,g:\bR^d \to \bC$ be $L^1$ functions. Then the function $$(f * g) (x) := \int_{\bR^d} f(x-y)g(y) dy$$ is almost an everywhere well defined function $\bR^d \to \bR$ that is $L^1$.

\end{prop}

\begin{proof} By Tonelli's theorem (Fubini's theorem for positive functions that are not necessarily $L^1$) we have that $$\int_{\bR^d \times \bR^d} |f(x-y)||g(y)|dx dy = \left(\int_{\bR^d} |f(x-y)| dx \right) \left( \int_{\bR^d} |g(y)| dy \right) < \infty$$ thus we have that $$\int_{\bR^d} |f(x-y)||g(y)| dy < \infty$$ for almost all $x$. Thus $(f*g)(x)$ is well defined for almost all $x$. It also follows from Fubini's theorem that $(f*g)$ is Lebesgue measurable (almost Borel). Finally, the inequality above also shows it is in $L^1(\bR^d)$ and in fact the $L^1$ norm bounded by the product of the $L^1$ norms. \end{proof}

Convolution is commutative (use translation invariance) and bilinear. It also preserves properties like continuity and differentiability as follows.

\begin{prop} Suppose that $\phi \in C_0(\bR^d)$ and $ g \in L^1(\bR^d)$ and $\phi$ is $n$ times continuously differentiable (where $n \in \bZ_{\geq 0}$). Then $\phi*g$ is $n$ times continuously differentiable, everywhere defined and $$\partial^{\alpha} (\phi * g) = (\partial^{\alpha} \phi) * g$$ whenever $|\alpha|\leq n$.

\end{prop}

\begin{proof} We just focus on the $n=1$ and $n=0$ cases and the rest follows from induction. For the $n=0$ case we just have to show that $\phi * g$ is continuous if $\phi$ is continuous and $g \in L^1(\bR^d)$. As $\phi$ is compactly supported, it is uniformly continuous and so we have that $$\phi(x+h) - \phi(x) \to 0 \text{ uniformly on } \bR^d \text{ as } h \to 0.$$ It now follows that, for each fixed $x \in \bR^d$, we have that $$(\phi * g)(x+h) - \phi*g(x) = \int_{\bR^d} (\phi*(x+h-y) - \phi*(x-y)) g(y) \to 0$$ as $h \to 0$ by the dominated convergence theorem. Now assuming that $\phi$ is once continuously differentiable and letting $\partial_1 = \frac{\partial}{\partial x_1}$ we must show that $$
\lim_{t \to 0} \frac{(\phi * g)(x+ te_1) - (\phi *g)(x)}{t} = ((\partial_1 \phi) * g)(x).$$

By the mean value theorem\footnote{To apply it we have to assume $\phi$ is real valued, but it is easy to see that it is enough to consider this case.}, we have that $\frac{1}{t}(\phi(x+ te_1) - \phi(x) )= \partial_1 \phi (x + s_{t,x}e_1)$ for some $0 \leq s_{t,x} \leq t$. Thus by uniform continuity of $\partial_1 \phi$ we have that $$\frac{1}{t} (\phi(x+ te_1) - \phi(x)) \to \partial_1(\phi)(x) $$ uniformly for $x \in \bR^d$ as $t \to 0$. We now by the dominated convergence theorem that

\begin{align*} \frac{(\phi * g)(x+ te_1) - (\phi *g)(x)}{t} &= \int_{\bR^d} \frac{\phi(x-y+ te_1) - \phi(x-y)}{t} g(y) dy \\ &\to \int_{\bR^d} (\partial_1\phi(x-y)) g(y) dy \\ &= ((\partial_1 \phi) * g)(x) \end{align*} as $t \to 0$. \end{proof}

\begin{prop} Suppose that $f_n,f,g \in L^1(\bR^d)$ are such that $\| f_n -f\|_{\infty} \to 0$. Then $|(f_n *g) - (f*g)|_{\infty} \to 0$.

\end{prop}

\begin{proof}

For each $x \in \bR^d$ we have $$|(f_n * g) (x) - (f*g)(x)| = |\int_{\bR^d} (f_n(x-y) - f(x-y)) g(y)| \leq |f - f_n|_{\infty} \int_{\bR^d} |g(y)| dy$$ and thus we have uniform convergence. \end{proof}

\begin{corol} The space $D(\bR^d)$ is closed under convolution. Moreover, if $\phi_n \to \phi$ in $D(\bR^d)$ then $\phi_n * \psi \to \phi * \psi$ in $D(\bR^d)$ for all $\psi \in D(\bR)$.

\end{corol}

\begin{proof} If $$0 \neq (\phi * \psi) (x) = \int \phi(x-y) \psi(y) dy$$ then there exists $y$ such that $x-y \in \operatorname{supp} \phi $ and $y \in \operatorname{supp} \psi$. Thus $x \in \operatorname{supp}(\phi) + \operatorname{supp}(\psi)$, which is a compact set. Thus $\phi * \psi$ is compactly supported. By the proposition above is smooth, thus $D(\bR^d)$ is indeed closed under convolution.  Now if $\phi_n \to \phi$, then there is some compact set $K$ containing the supports of all $\phi_n, \phi$ and $\psi$ and we have uniform convergence of all partial derivatives $\partial^{\alpha} \phi_n \to \partial^{\alpha} \phi$ thus we have uniform convergence $(\partial^{\alpha} \phi_n) * \psi \to (\partial^{\alpha} \phi) * \psi$ and all these functions are supported on a single compact set $K + K$. Finally, using the identity $\partial^{\alpha} (\phi * \psi) = (\partial^{\alpha} \phi) * \psi$ the proof is complete.  \end{proof}

We now show that a convolution can be approximated by an average of translations. This is useful for establishing certain density results.

\begin{prop}\label{prop: convolution is approximate average} Let $f,g:\bR^d \to \bR$ be uniformly continuous bounded $L^1$ functions and suppose $g$ has compact support. Then $$(f * g)(x) = \lim_{N \to \infty} \frac{1}{N^d} \sum_{y \in \frac{1}{N^d}\bZ^d} f(x-y) g(y)$$ where the limit is uniform on $x \in \bR^d$. In particular, $(f*g)$ is a uniform limit of finite linear combinations of transates of $f$.

\end{prop}

\begin{proof} Let for $y \in \frac{1}{N}\bZ^d$, let $$Q_{y,N} = \left[y_1, y_1 + \frac{1}{N}\right) \times \cdots \times \left[y_d, y_d + \frac{1}{N}\right) $$ be the cube of side-length $\frac{1}{N}$ whose leftmost bottom corner is $y$. Fix $\epsilon>0$. By uniform continuity and boundedness of $f$ and $g$, we may find a large enough $N_0$ such that if for $N>N_0$ we have that $$|f(x-y)g(y) - f(x-u)g(u)| < \epsilon \quad\text{for all } u \in Q_{y,N}, y \in \frac{1}{N}\bZ^d.$$ Now it follows that 

\begin{align*} (f * g)(x) &= \sum_{y \in \frac{1}{N}\bZ^d} \int_{Q_{y,N}} f(x-u)g(u) du \\ &= \sum_{y \in \frac{1}{N}\bZ^d} \frac{1}{N^d}(f(x-y)g(y) + E_{y,N})\end{align*} where $|E_{y,N}|<\epsilon$. However, notice that $E_{y,N} = 0$ if $Q_{y,N} \cap \operatorname{supp}(g) = \emptyset$. But there are $O(N^d)$ such $y$ since the support of $g$ is compact (if the support is inside $[-B,B)^d$ for some positive integer $B$, then there are $(2BN)^d$ such $y$). Thus the total error is $O(\epsilon) \to 0$ as $N_0 \to 0$. This demonstrates the uniform convergence. \end{proof}

\begin{prop}[Approximate identity]\label{prop: approx identity} Let $f:\bR^d \to [0,\infty)$ be an $L_1$ function such that $$\int_{\bR^d} f(x) dx = 1$$ and suppose that $g:\bR^d \to \bR$ is a compactly supported continuous function. Let $$f_{\epsilon}(x) = \frac{1}{\epsilon^d}f(\epsilon^{-1} x).$$ Then $$f_{\epsilon} * g \to g \quad \text{ uniformly on } \bR^d.$$

\end{prop}

\begin{proof} For each $r>0$, we let $$\Delta(r) = \sup_{x \in \bR^d} \{ |g(x+h) - g(x)| ~|~ \|h\| \leq r \}$$ and we observe that $\Delta(r) \to 0$ as $r \to 0$ by uniform continuity ($g$ is compactly supported).

\begin{align*} (f_{\epsilon} *g)(x) = \int_{\bR^d} f_{\epsilon} (y) g(x-y) dy &= \int_{|x| < r} f_{\epsilon}(y) g(x-y) dy + O(\| g \|_{\infty} \int_{|x|>r} f_{\epsilon}(y) dy) \\ &= \int_{|x| < r} f_{\epsilon}(y) g(x) dy + O(\Delta(r) \int_{|x| < r} f_{\epsilon}(y) dy )  + O(\| g \|_{\infty} \int_{|x|>r} f_{\epsilon}(y) dy) \end{align*} 

Now observe that since $$\int_{\bR^d} f_{\epsilon}(x) = 1$$ we have that for each $r>0$ fixed this quantity converges, as $\epsilon>0$, to $$g(x) + O(\Delta(r)).$$ But by uniform continuity, we can choose $r$ small enough so that this error term is arbitrarily small and thus get the desired uniform continuity as the the implicit $O()$ constant does not depend on $x$. \end{proof}

The previous two propositions have same nice applications to approximating a function by a nice class of functions. For instance, we now recover the Weierstrass approximation theorem for polynomials.

\begin{thm}[Weierstrass approximation] Let $g:\bR \to \bR$ be a compactly supported continuous function. Then for any compact set $K$ and $\epsilon >0$, there exists a polynomial $P(x) \in \bR[x]$ such that $\sup_{x \in K} |P(x) - g(x)| < \epsilon$.

\end{thm}

\begin{proof} We let $f:\bR \to [0,\infty)$ be an entire function (a function given by a power series with an infinite radius of convergence) that is bounded, uniformly continuous and such that $$\int f(x) dx = 1.$$ For example, we can take $$f(x) = C e^{-x^2} = C \sum_{n=0}^{\infty} \frac{(-1)^n}{n!} x^{2n}$$ for some approximately chosen constant $C$. Thus, for $\epsilon>0$, we obtain by Proposition~\ref{prop: approx identity} that for sufficiently small $\delta>0$ we have $$|g(x) - (f_{\delta}*g)(x)| < \frac{\epsilon}{2} \quad \text{for all } x \in \bR.$$ But now we use Proposition~\ref{prop: convolution is approximate average}  to show that $$|(f_{\delta}*g) (x) - h(x)| < \frac{\delta}{2} \quad \text{ for all } x \in \bR$$ where $$h(x) = \lim_{N \to \infty} \frac{1}{N^d} \sum_{y \in \frac{1}{N^d}\bZ^d} f_{\delta}(x-y) g(y). $$

Thus as the sum defining $h(x)$ is finite, we see that $h(x)$ is a finite linear combination of entire functions $x \mapsto f_{\delta}(x-y)$. Thus $\|g - h \|_{\infty} < \epsilon$. Finally, we finish the proof by using the uniform convergence of the power series for $f_{\delta}(x)$ for $x \in K$. \end{proof}

\section{Tensor Products of Distributions}

Given functions $\phi:X \to \bC$ and $\psi:Y \to \bC$, we define their tensor product $$\phi \otimes \psi:X \times Y \to \bC$$ to be $$(\phi \otimes \psi)(x,y) = \phi(x) \psi(y).$$ If $X,Y \subset \bR^d$ are open sets, then we let $$D(X) \otimes D(Y) \subset D(X \times Y)$$ denote the set of linear combinations of tensor product $$\{\phi \otimes \psi ~|~ \phi \in D(X), \psi \in D(Y) \}.$$

\begin{prop} Let $X,Y \subset \bR^d$ be open sets. Then space $D(X) \otimes D(Y)$ is dense in $D(X \times Y)$, that is, for any $\theta \in D(X \times Y)$ we can find a sequence $\theta_n \in D(X) \otimes D(Y)$ such that $$\theta_n \to \theta,$$ that is for each $\alpha \in \bZ^d_{\geq 0 }$ we have that $$\partial^{\alpha} \theta_n \to \partial^{\alpha} \theta$$ uniformly on some compact set $K$ that contains the support of all the $\theta_n$ and $\theta$.

\end{prop}

\begin{proof} The proof is similair to that of Weierstrass theorem given above. First, we let $\phi_1 \in D(\bR^d)$ and $\phi_2 \in D(\bR^d)$ be functions whose integral equals $1$. Now let $\phi = \phi_1 \otimes \phi_2$. Now define $$\phi_{\epsilon}(z) = \frac{1}{\epsilon} \phi(\epsilon z).$$ Observe that for small enough $\epsilon>0$ we have that $$\phi_{\epsilon} * \theta \in D(X \times Y)$$ since the support of $\phi_{\epsilon} * \theta$ is an arbitrarily small neighbhourhood of the support of $\theta \in D(X \times Y)$. It now follows from Proposition~\ref{prop: approx identity} that $\phi_{\epsilon} * \psi \to \psi$ uniformly for all $\psi \in D(X \times Y)$ and thus in particular  $$\partial^{\alpha} (\phi_{\epsilon}  * \psi) = \phi_{\epsilon} * (\partial^{\alpha} \psi) \to \partial^{\alpha} \psi$$ uniformly for all $\alpha \in \bZ^d_{\geq 0}$. In particular, this means that $\phi_{\epsilon} * \theta \to \theta$ in $D(X \times Y)$. It now suffices to show that each $$\phi_{\epsilon} * \theta $$ is the limit of some elements in $D(X) \otimes D(Y)$. But by Proposition~\ref{prop: convolution is approximate average}  we have the uniform limit $$(\partial^{\alpha}\phi_{\epsilon} * \theta) (x) = \lim_{N \to \infty} \frac{1}{N^d} \sum_{y \in \frac{1}{N}(\bZ^d)} (\partial^{\alpha} \phi_{\epsilon}(x-y)) \theta(y).$$ Thus we have written $\phi_{\epsilon} * \theta$ as a limit in $D(X \times Y)$ of linear combination of translates of $\phi_{\epsilon}$, which are clearly in $D(X) \otimes D(Y)$.\end{proof}

\begin{thm}[Tensor product of distributions] Let $u \in D'(X)$ and $v \in D'(Y)$ be two distributions, where $X,Y \subset \bR^d$ are open sets. Then there exists a unique distributions $u \otimes v \in D(X \times Y)$, called the tensor product of $u$ and $v$, such that $$(u \otimes v)(\phi \otimes \psi) = u(\phi) \cdot v( \psi) \quad \text{ for all } \phi \in D(X), \psi \in D(Y).$$ Moreover, the tensor product is given by the well defined formula $$(u \otimes v)(\theta) = u(y \mapsto (v(x \mapsto \theta(x,y)))).$$ 

\end{thm}

\begin{proof} Note that uniqueness follows from the fact that $D(X) \otimes D(Y)$ is dense in $D(X \times Y)$, thus any distribution on $D(X \times Y)$ is determined uniquely by its restriction to $D(X) \otimes D(Y)$. Now we show existence by showing that the claimed formula gives a well defined distribution. Firstly, to show that $v(x \mapsto \theta(x,y))$ is well defined we must show that $x \mapsto \theta(x,y)$ is smooth (and it is since $\theta$ is) and it is an element of $D(X)$, i.e., its support is a compact subset of $X$. Now since $\theta$ is an element of $D(X \times Y)$ we have that $\operatorname{supp} \theta$ is a compact subset of $X \times Y$. Now suppose that $x_0$ is in the support of $x \mapsto \theta(x,y)$. This this means that there is a sequence $x_1, x_2,\ldots \to x_0$ such that $\phi(x_i,y)>0$ and $x_0 \in X$. So in particular $(x_i,y) \in \operatorname{supp} \theta$ and $(x_i, y) \to (x_0,y)$, thus as the support is closed (by definition) we have that $(x_0,y) \in \operatorname{supp} \theta$. Thus we have shown that the support of $x \mapsto \theta(x,y)$ is contained in the projection onto $X$ of the set $\operatorname{supp}(\theta) \cap (X \times \{y\})$, and thus is compact subset of $X \times Y$. Thus $x \mapsto \theta(x,y)$ is an element of $D(X)$, so the expression $v(x \mapsto \theta(x,y))$ is well defined. 

Next, we must show that the map $V\theta:Y \to \bC$ defined by $y \mapsto v(x \mapsto \theta(x,y))$ is an element of $D(Y)$. We thus need to show it is smooth and has compact support inside $Y$. For smoothness, we let $\partial_i = \frac{\partial}{\partial y_i}$ denote partial differentiation with respect to the $i$th coordinate in $Y$. 

\textbf{Claim:} Let $\theta_y(x) = \theta(x,y)$, let $e_i$ be the $i$-th basis vector in $\bR^d$ and let $$\theta_{y,t} = \frac{\theta_{y+te_i}(x) - \theta_{y}(x)}{t}.$$ Then $\theta_{y,t} \in D(X)$ and it converges in $D(X)$ to the map $$(\partial_i \theta_y)(x) := (\partial_i\theta) (x,y).$$

\textbf{Proof of Claim:} For sufficiently small $t$ we have that $y+te_i \in Y$ as $Y$ is open, $\theta_{y+te_i} \in D(X)$ as we saw previously. Thus $\theta_{y,t} \in D(X)$ for sufficiently small $t$. But now by the mean value theorem we have that $$\frac{\theta_{y+te_i}(x) - \theta_y(x)}{t} = \partial_i \theta(x, y+s_{t,x}e_i)$$ for some $s_{t,x} \in [0,t]$. Thus by uniform continuity of $\theta$ we have that $$\frac{\theta_{y+te_i}(x) - \theta_y(x)}{t} \to (\partial_i \theta)(x,y) \text{ uniformly for }x \in X .$$ The same argument applies if we replace $\theta_{y}$ with any higher order partial derivative (with respect to the $x$ coordinates). Which shows the convergence in $D(X)$ (uniform convergence of all partial derivatives). QED of claim.

But now the claim implies that $$\frac{V\theta (y+te_i) - V\theta(y)}{t} = v(\theta_{y,t}) \to v((\partial_i\theta)_{y,t}) = V(\partial_i \theta)$$ thus $V\theta$ is differentiable and hence smooth by applying inductively the argument to $V(\partial_i \theta)$. To show that $V\theta \in D(Y)$ it now remains to show that the support of $V\theta$ is a compact subset of $X$. Thus suppose that $V(\theta)(y) \neq 0$. Then clearly $x \mapsto \theta(x,y)$ cannot be the zero function and thus $(x,y) \in \operatorname{supp}(\theta)$ for some $x \in X$. It now follows by projection onto $Y$ that $y$ is contained in the projection onto $Y$ of the support of $\theta$, which must be a comapct set. Thus $V\theta$ is indeed in $D(Y)$. This now completes the proof that the expression $$(u \otimes v)(\theta) = u(y \mapsto (v(x \mapsto \theta(x,y))))$$ is well defined (gives a well defined number on the right hand side). 

Now we must show that $(u \otimes v)$ is a distribution (continuous linear functional). Linearity is clear. For continuity, suppose now that  $\theta_1, \theta_2, \ldots \to \theta$ in $D(X \times Y)$. Then the map $$x \mapsto \theta_i(x,y)$$ converge in $D(X)$ to $$x \mapsto \theta(x,y)$$ and thus continuity of $v$ implies that the maps $$V(\theta_i): y \mapsto (v(x \mapsto \theta_i(x,y)))$$ converge to the map $V\theta$ pointwisely. We must do better: we must show that this convergence is uniform for $\theta$ and also for all it partial derivatives. As $\partial^{\alpha}V(\theta) = V(\partial^{\alpha}\theta)$ as shown above, it is enough to show the uniform convergence of $\theta$ and it will follow for partial derivatives. By linearity, let us assume that $\theta = 0$ is the zero function. Now let $K \subset X$ be a compact set that contains all the supports of the $(\theta_i)_y$ (there is a single compact subset of $X \times Y$ containing all the supports of the $\theta_i$, so we just take $K$ to be the projection of that). Now by Theorem~\ref{thm: distributions are lipschitz on compact sets} we have a constant $c>0$ and integer $k>0$ such that for all $i=1,2,\ldots$ and $y \in Y$ we have that $$ |v((\theta_i)_y)| \leq c\| (\theta_i)_y \|_{C_k} .$$ Thus since the $\theta_i \to \theta = 0$ in $D(X \times Y)$ we have for each $\alpha \in \bZ_{\geq 0}^d$ that $\partial^{\alpha} (\theta_i)_y \to \partial^{\alpha} \theta_y $ uniformly accross all $y$. Thus $v((\theta_i)_y)$ converges to $0$ uniformly in $y$.

Finally, if $\phi_1 \in D(X)$ and $\phi_2 \in D(Y)$ then $$(u \otimes v)(\phi_1 \otimes \phi_2) = v(y \mapsto u(x \mapsto \phi_1(x)\phi_2(y))) = v(y \mapsto \phi_2(y) u(\phi_1)) = u(\phi_1)v(\phi_2)$$ and so this construction does indeed satisfy the definition of a tensor product. \end{proof}


\section{Convolution of Distributions}

\subsection{Well defined convolutions of distributions}

\begin{lemma}\label{lemma: translated distribution} Let $v \in D'(\bR^d)$ be a distribution, then for $x \in \bR^d$ the map define the distribution $T_x v \in D'(\bR^d)$ given by $$T_x v (\phi) = v(y \mapsto \phi(x+y)).$$ Then for each $\phi \in D(\bR^d)$ the mapping $$F_{\phi} : x \mapsto T_x v(\phi)$$ is smooth. In particular $(\partial^{\alpha}F_{\phi})(x) = v(y \mapsto \partial^{\alpha}\phi(x+y)) = F_{\partial^{\alpha} \phi}(x).$

\end{lemma}

\begin{proof} Letting $e_i$ be a standard basis vector, we see that $$\frac{1}{t} (T_{x+t e_i}v (\phi) - T_{x}v(\phi)) = v\left( y \mapsto \frac{\phi(x+te_i + y) - \phi(x+y)}{t} \right).$$ Now by the mean value theorem we see that  $$\frac{\phi(x+te_i + y) - \phi(x+y)}{t} = (\partial_i\phi)(x+ s e_i+y)$$ for some $0 \leq s \leq t$. By uniform continuity of partial derivatives of $\phi$, we see that $$\frac{\phi(x+te_i + y) - \phi(x+y)}{t} \to (\partial_i \phi)(x+y) \text{ uniformly over } x,y \in \bR^d \text{ as } t \to 0.$$ We can replace $\phi$ by any of its partial derivatives and obtain the same uniform convergence for its partial derivatives. Thus the convergence to $(\partial_i \phi)(x+y)$ occurs in $D(\bR^d)$. Thus by the continuity of $v$ we get that $$\frac{1}{t} (T_{x+t e_i}v (\phi) - T_{x}v(\phi)) \to v(y \mapsto (\partial_i \phi)(x+y)) \quad \text{ as } t \to \infty.$$ Thus we obtain the relation that $$(\partial_i F_{\theta})(x) = v(y \mapsto (\partial_i\phi)(x+y)).$$ But the right hand side is clearly equal to $$T_x v(\partial_i\phi) = F_{\partial_i \phi}(x)$$ and so we obtain the smoothness of $F$ and the stated formula for its partial derivatives by repeatedly applying this relation. \end{proof}

\begin{eg} We have $$T_x \delta_a = \delta_{a+x}$$ where $\delta_a(\phi) = \phi(a)$ is the point mass at $a \in \bR^d$.

\end{eg}

We define $T_{-x}\phi(y) = \phi(x+y)$ for functions $\phi$ on $\bR^d$ and $x \in \bR^d$.

\begin{lemma}\label{lemma: T_x v continuous} If $v \in D(\bR^d)$ and $\phi_1, \phi_2 \ldots \in D(\bR^d)$ converge to $\phi \in D(\bR^d)$ in $D(\bR^d)$ then for each compact $K \subset \bR^d$ we have that $$T_x v (\phi_i) \to T_xv (\phi) \quad \text{uniformly for } x \in K.$$

\end{lemma}

\begin{proof} Fix a compact set $K \subset \bR^d$. By linearity, we only need to show the case $\phi=0$. Now since $\phi_i$ converge in $D(\bR^d)$ we may find compact set $K' \supset K$ such that each of the compactly supported functions $T_{-x} \phi_i(y)$ for $x \in K$ and $i \in \{1,2,\ldots \}$ have support inside $K'$. It follows that we may now apply Theorem~\ref{thm: distributions are lipschitz on compact sets} to the compact set $K'$ and find a constant $c>0$ and integer $k>0$ such that for all $x \in K$ and $i \in \bN$ we have that $$v(T_{-x}\phi_i) \leq c \| T_{-x}(\phi_i) \|_{C_k}.$$ Now since the $\phi_i$ and all its partial derivatives converge uniformly to $0$, we see that $T_{-x}\phi_i$ must also converge uniformly to $0$ at the same rate for $x \in K$ (translation preserves maximum of absolute values of functions). Thus $v(T_{-x}\phi_i) \to 0$ uniformly for $x \in K$. \end{proof}

The previous two lemmata now show that the convolution of a compactly supported distribution and another distribution is well defined.

\begin{mydef} If $u \in \mathcal{E}'(\bR^d)$ and $v \in D'(\bR^d)$ are distributions with $v$ compactly supported then we can define their convolution $u * v \in D'(\bR^d)$ by the formula $$(u * v)(\phi) = u(x \mapsto v(y \mapsto \phi(x+y))).$$ If instead we assume $u \in D'(\bR^d)$ and $v \in \mathcal{E}'(\bR^d)$ then the conolution is also a well defined distribution.

\end{mydef}

\begin{proof}[Proof of well definedness] More precisely, this is well defined in the case $u \in \mathcal{E}'(\bR^d)$ and $v \in D'(\bR^d)$ since by Lemma~\ref{lemma: translated distribution} we have that the inner term $x \mapsto v(y \mapsto \phi(x+y))$ is a smooth function and since $u \in \mathcal{E}'(\bR^d)$ it is defined on the space $C^{\infty}(\bR^d)$ of smooth functions (that are not necessarily compactly supported). Thus the expression $(u * v)(\phi)$ is well defined. Now, it defines a distribution (continuous) since if $\phi_i \to \phi$ in $D(\bR^d)$ then by Lemma~\ref{lemma: T_x v continuous} we have that $$x \mapsto v(y \mapsto \phi_i(x+y))$$ converge uniformly to $$x \mapsto v(y \mapsto \phi(x+y))$$ on compact sets $K$ and thus by the definition of convergence in $\mathcal{E}'(\bR^d)$ we have that $(u * v)(\phi_i) \to (u*v)(\phi)$, thus $u * v$ is a distribution (continuous linear functional).

Now consider the other case $u \in D'(\bR^d)$ and $v \in \mathcal{E}'(\bR^d)$. Then the inner map $$x \mapsto v(y \mapsto \phi(x+y))$$ has compact support since for large enough $y$, we have that $v$ and $x \mapsto \phi(y+x)$ will have disjoint supports, hence the expression $(u * v)(\phi)$ is well defined in this case. Now we show continuity. Suppose $\phi_i \to 0$ in $D(\bR^d)$. Then there is a compact set $K$ containing the supports of all the $\phi_i$. Thus each map $y \mapsto \phi_i(x+y)$ is supported on the compact set $K-x$. But for all large enough $x$, the support of $v$ is disjoint from $K-x$. Thus for large enough $x$ we have that $$v(y \mapsto (\phi_i (x+y))) = 0 \text{ for all } i \in \bN.$$ Therefore indeed the map $$x \mapsto v(y \mapsto (\phi_i (x+y)))$$ are supported on a single compact set and converge in $D(\bR^d)$ (by Lemma~\ref{lemma: T_x v continuous}) to $0$. Thus by continuity of $u$, we have that $(u*v)(\phi) \to 0$ and thus $u*v$ is continuous. \end{proof}

\begin{eg} If $\delta_a$ is the point mass at $a \in \bR^d$ and $u \in D'(\bR^d)$. Then $$(\delta_a * u) = \delta_a(x \mapsto u(y \mapsto \phi(y+a))) = u(y \mapsto \phi(y+a)).$$ In particular $\delta_0 * u = u$. Now if $u(\phi) = \int f(x) \phi(x) dx$ for some locally integrable function $f$. Then $$(\delta_a * u) = \int f(y)\phi(y+a) dy = \int f(y-a)\phi(y) dy.$$ Thus $\delta_a * u$ has a density function $f(y-a)$, so convolution with $\delta_a$ translates the density by $a$. Moreover, we have that $$\delta_a * \delta_b (\phi) = \delta_a(x \mapsto \delta_b(y \mapsto \phi(x+y))) = \delta_b (y \mapsto \phi(a+y)) = \phi(a+b) = \delta_{a+b}(\phi).$$ Thus $$\delta_a * \delta_b = \delta_{a+b}.$$

\end{eg}


\begin{eg} If $u$ is not compactly supported then this formula may not be well defined. For example if $u,v$ are both the uniform measure on $\bR$ then $u*v(\phi) = \infty$ for any positive function $\phi$, thus not a distribution. An even more pathalogical example arises if $$u = \sum_{n \in \bZ} (-1)^n Lebesgue_{[n,n+1)}$$ is a signed measure which is still a well defined distribution.

\end{eg}

Now observe that if $f,g:\bR^d \to \bC$ are locally integrable functions then they may be defined naturally as distributions. We now show that their convolution as distributions is the same as their convolution as functions. To see this, let $\phi \in D(\bR^d)$, then 

\begin{align*} (f * g)(\phi) &= \int_{\bR^d} (f*g)(x) \phi(x) dx \\ &= \int_{\bR^d} \left( \int_{\bR^d} f(y)g(x-y) \phi(x) dy \right) dx \\ &= \int_{\bR^d} f(y)  \left( \int_{\bR^d} g(x-y)\phi(x) dx \right)  dy \\ &=  \int_{\bR^d} f(y)  \left( \int_{\bR^d} g(x)\phi(x+y) dx \right)  dy \\ &= f(y \mapsto g(x \mapsto \phi(x+y))) \end{align*} where our use of Fubini's theorem is justified by the fact that $f(y)g(x-y)$ is an $L^1$ map on $\bR^d \times \bR^d$ as justified in the proof of Proposition~\ref{prop: convolution of L1 is L1} and thus so is $f(y)g(x-y)\phi(x)$ as $\phi$ is bounded. Thus we see that the the convolution as functions gives rise to the distribution obtained by taking the convolution as distributions, where we assume either $f$ or $g$ has compact support for the definition of convolution of distributions to be valid.

\subsection{Convolution of a compactly supported smooth function and a distribution}

Next, we attempt to compute $\psi * u$ where $\psi \in C_0^{\infty}(\bR)$ is a compactly supported smooth function. The idea behind the next lemma is that convolution of distributions is bilinear and so must preserve linear combinations, yet convolutions of functions are approximate linear combinations. We let $(S\psi)(x) = \psi(-x)$.

\begin{lemma} Let $\psi \in C_0^{\infty}(\bR^d)$ and let $u \in D'(\bR^d)$. The for all $\phi \in  D(\bR^d)$ we have that $$(\psi * u)(\phi) = u((S\psi) * \phi).$$

\end{lemma}

\begin{proof} We have by Proposition~\ref{prop: convolution is approximate average} that \begin{align}\label{eq: psi*phi convolution approx} (\psi * \phi)(x) = \lim_{N \to \infty} \frac{1}{N^d} \sum_{y \in \frac{1}{N^d}\bZ^d} \psi(y) \phi(x-y) \end{align} where the limit is uniform for $x \in \bR^d$. Observe also that for all $N$, the right hand side is support on the compact set $K = \operatorname{supp}(\phi) + \operatorname{supp}(\psi)$. Note that by compactness of the support, this sum is finite for each $N$. Applying Proposition~\ref{prop: convolution is approximate average} to any partial derivative of $\phi$ we also get 

\begin{align*} \partial^{\alpha}(\psi * \phi)(x) &= \psi * (\partial^{\alpha} \phi)(x) \\ &= \lim_{N \to \infty} \frac{1}{N^d} \sum_{y \in \frac{1}{N^d}\bZ^d} \psi(y) (\partial^{\alpha}\phi)(x-y) \\&= \lim_{N \to \infty} \partial^{\alpha}\left(\frac{1}{N^d} \sum_{y \in \frac{1}{N^d}\bZ^d} \psi(y) \phi(x-y) \right)  \quad\text{uniformly for } x \in K \end{align*} where of course in the final expression the partial derivative is with respect to $x$ and $\psi(y)$ is just a constant. Thus we have shown that the convergence $(\ref{eq: psi*phi convolution approx})$ is actually in $D(\bR^d)$. Thus we may use the continuity of $u$ to conclude that $$u(\psi * \phi) = \lim_{N \to \infty} \frac{1}{N^d}  \sum_{y \in \frac{1}{N^d}\bZ^d} \psi(y) u(x \mapsto \phi(x-y)).$$ Now we can interpret the right hand side as a Riemann sum approximation for the functions $F(y) = \psi(y)u(x \mapsto \phi(x-y))$ which we know is smooth hence Riemann integrable. Note that the sum is finite for each $N$ as $\psi$ is compactly supported. We thus obtain that $$u(\psi * \phi) = \int_{\bR^d} \psi(y)u(x \mapsto \phi(x-y)) dy = \int_{\bR^d} (S\psi)(y) u(x \mapsto \phi(x+y)) dy$$ where we applied the Lebesgue measure preserving map $y \mapsto -y$. But this right hand side is precisely the convolution product $$(S\psi)( y \mapsto u(x \mapsto\phi(x+y))) = (S\psi) * u.$$ This is clearly equivalent to what we wanted to show since $SS\psi = \psi.$ \end{proof}

Next, we show that the convolution of a compactly supported smooth function and a distribution is a smooth function (more precisely, the distribution corresponding to a smooth function).

\begin{thm}  Let $\psi \in C_0^{\infty}(\bR^d)$ and let $u \in D'(\bR^d)$. Then $\psi * u \in C^{\infty}(\bR^d)$, where we embed $C^{\infty}(\bR^d)$ into $D'(\bR)$ as usual. In particular, $$(\psi * u) (x) = u(y \mapsto \psi(y-x)) .$$

\end{thm}

\begin{proof} If $\phi \in D(\bR)$ then we have 

\begin{align*} (\psi * u)(\phi) &= u(S\psi * \phi) \\ &= u(SS\phi * S\psi) \\ &= (S\phi * u)(S\psi) \\ &= \int_{\bR^d} (S\phi) (x) u(y \mapsto S\psi(x+y)) dx = \int_{\bR^d} \phi(-x) u(y \mapsto \psi(-x-y) dx \\ &= \int_{\bR^d} \phi(x) u(y \mapsto \psi(x-y)) dx. \end{align*}

Thus the distribution $\psi * u$ has a density function $x \mapsto u(y \mapsto \psi(y-x))$ which we know is smooth.

\end{proof}

\subsection{Applications: approximating a distribution with a smooth function}

\begin{lemma} If $u_n \to u$ in $\mathcal{E}'(\bR)$ then $u_n * v \to u_n * v$ in $D'(\bR)$ for $v \in D'(\bR)$. 

\end{lemma}

\begin{proof} For any $\phi \in D(\bR)$ we have that $$(u_n * v)(\phi) = u_n(x \mapsto v(y \mapsto \phi(x+y))) \to u(x \mapsto v(y \mapsto \phi(x+y))) = (u*v)(\phi).$$

\end{proof}

We can now show that any distribution is a limit of compactly supported smooth functions.

\begin{thm} The space $C_0^{\infty}(\bR^d)$ is a dense subspace of $D'(\bR^d)$. Moreover, if $u \in D'(\bR^d)$ has compact support, then there exists a compact set $K \supset \operatorname{supp} u$ and $\theta_n \in C_0^{\infty}(\bR^d)$  such that all $\theta_n$ have support inside $K$ and $\theta_n \to u$ in $\mathcal{E}'(\bR^d)$.

\end{thm}

\begin{proof} Let $u \in D'(\bR^d)$ be a distribution. We can find a sequence of functions $\psi_n \in C_0^{\infty}(\bR^d)$ such that $\psi_n \to \delta$ in $\mathcal{E}'(\bR^d)$ and $\psi_n$ all have support inside $[-1,1]^d$. It now follows that $$\psi_n * u \to \delta * u = u$$ in $D'(\bR^d)$. However we know that $\psi_n * u \in C^{\infty}(\bR^d)$ corresponds to the smooth function $$\theta_n(x) = u(y \mapsto \psi_n(y-x)).$$ Now $\theta_n$ does not necessarily have compact support. Let $\chi_n:\bR^d \to [0,1]$ be a sequence of smooth functions with compact support such that $\chi_n(x)=1$ for $\|x \| \leq n$. Thus $\chi_n \theta_n \in C_0^{\infty}(\bR^d)$. Now suppose $\phi \in D'(\bR^d)$, thus the support of $\phi$ is contained in a ball of radius $n_0$ for some positive integer $n_0$. For $n\geq n_0$ we thus have that $$(\chi_n\theta_n) (\phi) = \int_{\bR^d} \chi_n(x) dx \theta_n(x) \phi(x) dx = \int_{\bR^d} \theta_n(x)\phi(x) dx = \theta_n(\phi) \to u(\phi). $$ Thus $\chi_n \theta_n \to u$ in $D(\bR^d)$.

Now suppose that $u$ has compact support. Then if $\theta_n(x) \neq 0$ then we must have $\psi_n(y-x) \neq 0$ for some $y \in \operatorname{supp}\phi$ and thus $y-x \in [-1,1]^d$ and so $x \in K = [-1,1]^d + \operatorname{supp} u$. Hence all these maps $\theta_n$ have support inside the compact set $K \supset \operatorname{supp} u$. We know that $\theta_n \to u$ in $D'(\bR^d)$ but now let us show that the convergence occurs in $\mathcal{E}'(\bR^d)$ as well. Thus suppose that $\varphi \in C^{\infty}(\bR^d)$ is a smooth function (not necessarily of compact support). Then there exists a large enough integer $R$ such that $K$ is inside the ball of radius $R$ around $0$. Now it follows that $$\theta_n(\varphi) = \int_{\bR^d} \theta_n(x)\varphi(x) dx = \int_{\bR^d} \theta_n(x)\varphi(x)\chi_R(x) dx = \theta_n(\chi_R \varphi) \to u(\chi_R\varphi) = u(\varphi) $$ where in the last equality we used that the support of $u$ is inside $K$. Thus indeed the convergence occurs in $\mathcal{E}'(\bR^d)$. \end{proof}

\subsection{Commutativity}

We now that the convolution of two $L^1$ functions is commutative. We now address the question for distributions.

\begin{lemma} Let $\psi \in C_0^{\infty}(\bR^d)$ and $u \in D'(\bR^d)$. Then $u * \psi = \psi * u$.

\end{lemma}

\begin{proof} Let $\phi \in D(\bR^d)$. We know that $$(\psi * u)(\phi) = u(S\psi * \phi) = u\left(x \mapsto \int (S\psi)(y) \phi(x-y) dy \right).$$ But 

\begin{align*} (u*\psi)(\phi) &= u(x \mapsto \psi(y \mapsto (\phi(x+y)))) \\ &= u\left( x \mapsto \int_{\bR^d} \psi(y)\phi(x+y) dy \right) \\ &= u\left( x \mapsto \int_{\bR^d} (S\psi)(y)\phi(x-y) dy \right)  \end{align*} 

where in the last line we made the substituion $y \mapsto -y$. Thus we have the desired equality. \end{proof}

\section{Fourier Transform of Schwarz Functions}

\subsection{Definition and Riemann-Lebesgue Lemma}

\begin{mydef} If $u \in L^1(\bR)$ is integrable, then we define the Fourier transform $\mathcal{F}u:\bR^d \to \bC$ by $$\mathcal{F}u(\omega) = \int_{\bR^d} u(x) e^{-2\pi i \langle x, \omega \rangle } d\omega.$$

\end{mydef}

Note that this is well defined since $|e^{-2\pi it}| = 1$ for $t \in \bR$, thus $$|\mathcal{F}u(x)| \leq \int_{\bR^d} |u(\omega)| dx = \| u \|_1. $$ Thus $\mathcal{F}u$ is a bounded function on $\bR^d$.

\begin{prop} If $u \in L^1(\bR^d)$ then the Fourier transform $\mathcal{F}u:\bR^d \to \bC$ is  uniformly continuous bounded function on $\bR^d$.

\end{prop}

\begin{proof} We see that $$|\mathcal{F}u(\omega + \eta) - \mathcal{F}u(\omega)| = |\int_{\bR^d} u(x) e^{-2\pi i \langle \omega, x \rangle }(e^{-2\pi i \langle \eta, x \rangle}  - 1)dx| \leq \int_{\bR^d} |u(x) (e^{-2\pi i \langle \eta, x \rangle}  - 1) |dx.$$ As this upper bound is independent of $\omega$, uniform continuity of $\mathcal{F}u$ will follow once we show this upper bound converges to zero as $\eta \to 0$. But this follows from the dominated convergence theorem as the integrand converges pointwise to $0$ as $\eta \to 0$ and the integrand is bounded for all $\eta$ by the integrable function $2|u| $. \end{proof}

\begin{eg} Let $\mathds{1}_{[a,b]} \in L^1(\bR)$ be the indicator function of an interval where $a<b \in \bR$. Then $$\mathcal{F}\mathds{1}_{[a,b]}(\omega) = \int_a^b e^{-2\pi i \omega x} dx = \frac{e^{-2\pi i \omega a} - e^{-2\pi i \omega b}}{2\pi i \omega}.    $$ More generally, if $B = [a_1, b_1] \times \cdots \times [a_d, b_d]$ is a  box in $\bR^d$ then the Fourier transform of its indicator function is $$\mathcal{F}\mathds{1}_B ((\omega_1, \ldots, \omega_d)) = \prod_{j=1}^d  \frac{e^{-2\pi i \omega_j a} - e^{-2\pi i \omega_j b}}{2\pi i \omega_j}.$$

We now show that $$\lim_{\omega \to \infty} \mathcal{F}\mathds{1}_B(\omega)  \to 0.$$ This is clear in one dimension ($d=1$) as it is $O(\frac{1}{|\omega|})$. In higher dimensions, we have the upper bound $$O(\frac{1}{\max_{j} |\omega_j|})$$ which also converges to $0$ as $\omega \to \infty$. 

\end{eg}

The decay at infinity for the Fourier transform given above actually holds more generally as follows.

\begin{thm}[Riemann-Lebesgue Lemma] Let $u \in L^1(\bR^d)$. Then $$\lim_{\omega \to \infty} \mathcal{F}u(\omega) = 0.$$ More precisely, for all $\epsilon>0$ there exists an $R>0$ such that if $\|\omega \|>R$ then $|\mathcal{F}u(\omega)| < \epsilon$.

\end{thm}

\begin{proof} We know this is true if $u$ is the indicator function of a box, as seen in the example above. Thus, it is also true if $u$ is a linear combination of such functions. Thus the theorem is true on a dense subset of $L^1(\bR^d)$. Now suppose that $u_1, u_2 \in L^1(\bR^d)$ are such functions that converge to $u \in L^1(\bR^d)$. Then $$\|\mathcal{F}u - \mathcal{F}u_j \|_{\infty} \leq \|u - u_j\|_1 \to 0.$$ Thus $\mathcal{F}u_j \to \mathcal{F}u$ uniformly. But it follows that if $g_j:\bR^d \to \bC$ are continuous functions that vanish at $\infty$, then any uniform limit $g:\bR^d \to \bC$ of such functions also vanishes at infinity. To see this, suppose that $\epsilon>0$, then there exists $j_0$ such that for $j\geq j_0$ we have that $|g_j(x)-g(x)| < \frac{\epsilon}{2}$ for all $x \in \bR^d$. For any such fixed $j$, there exists $R$ such that $|g_j(x)|< \frac{\epsilon}{2}$ for $|x|>R$. Thus $$|g(x) - 0| \leq |g(x) - g_j(x)| + |g_j(x) - 0| < \epsilon $$ for all $|x|>R$. \end{proof}

\subsection{Fourier-Laplace transform}

We defined the Fourier transform has a function on $\bR^d$. We now consider whether, with $d=1$, we can naturally extend the Fourier transform to $\bC$.

Thus we define $$\mathcal{F}u(z) = \int_{\bR} u(x) e^{-2\pi i x z} dx$$ for $z \in \bC$ \textit{if the integral absolutely converges}. This need not be the case, for example if $z=i$ and $$u(x) = \frac{1}{1+x^2}$$ which is $L^1$ then the integral is $$\int_{\bR^d} \frac{e^{2\pi x}}{1+x^2} dx = \infty.$$

\begin{eg} If $u(x) = e^{-\alpha x^2}$ for some $\alpha >0$, then we have absolute convergence for any $z \in \bC$ since the integrand is bounded by $e^{-\frac{1}{2}\alpha x^2}$ for sufficiently large $x$.

\end{eg}

In fact, let us be a bit more general. Let $\mu$ be a signed Borel measure that is the difference of two finite positive Borel measures (for example, and probability measure or a measure with a density in $L^1(\bR$)). Then define the Fourier-Laplace transform as $$\mathcal{F}\mu (z) = \int_{\bR} e^{-2\pi i x z} d\mu(x)$$ for $z \in \bC$ where this integral absolutely converges.

\begin{prop}[Fourier-Laplace is holomorphic] Suppose that $\mu$ is a difference of finite positive measures on $\bR$. Let $U \subset \bC$ be an open set such that for all $z \in U$ we have $$\int_{\bR}| e^{-2\pi i x z} |d\mu(x) < \infty.$$ Then $$\mathcal{F}\mu(z) =  \int_{\bR} e^{-2\pi i x z} d\mu(x)$$ defines a holomorphic function of $z$ on $U$, where the integral absolutely converges, with derivative $$(\mathcal{F}\mu)'(z) = \int_{\bR} -2\pi i x z e^{-2\pi i x z} d\mu(x) $$ where again the integral absolutely converges.

\end{prop}

\begin{proof} We wish to compute the limit as $w \in \bC$ tends to $0$ of $$\frac{\mathcal{F}u(z+w) - \mathcal{F}u(z)}{w} = \int_{\bR} e^{-2\pi i xz} \left( \frac{e^{-2\pi xw i} - 1}{w} \right) dx.$$

Now clearly as $w \to 0$ then the integrand converges to the correct value. Thus, by the Lebesgue dominated convergence theorem, it remains to establish that for sufficiently small $w$ the integrand can be bounded by a single integrable function. From the mean value inequality, it follows that $$\left| \frac{e^{-2\pi xw i} - 1}{w} \right| = \sup_{t \in [0,1]} \left | \frac{\partial}{\partial z}|_{z = tw} e^{-2\pi i x z} \right | \leq 2\pi |x| e^{2\pi xw}.$$ Now as $z \in U$, we can find small enough $\epsilon>0$ such that the ball of radius $2\epsilon$ around $z$ is a subset of $U$. Now there exists a constant $C_{\epsilon}>0$ such that $$|x| < C_{\epsilon} (e^{2\pi \epsilon x} + e^{-2\pi \epsilon x}) \text{ for all } x \in \bR.$$ We can thus bound the integrand 

\begin{align*} \left | e^{-2\pi i xz} \left( \frac{e^{-2\pi xw i} - 1}{w} \right) \right | &\leq |e^{-2\pi i x z}| \cdot  2\pi |x|e^{2\pi x w} \\ &\leq 2\pi C_{\epsilon} (|e^{-2\pi i x z + 2\pi x w - 2\pi \epsilon x }| + |e^{-2\pi i x z + 2\pi x w + 2\pi \epsilon x}| ). \end{align*}

Now if we assume $|w| \leq \epsilon$, we get that these terms in the upper bound are of the form $2\pi C_{\epsilon} |e^{-2\pi i x (z + \delta)}|$ where $|\delta| \leq \epsilon + \epsilon \leq 2\epsilon$. Thus they are of the form $|e^{-2\pi i x u}|$ where $u \in U$. Thus by assumption that this integral absolutely converges for $z \in U$, so we have the desired upper bound for $|w| \leq \epsilon$ so the uniform convergence theorem applies. \end{proof}

\begin{eg}\label{eg: FT of Gaussian} The Fourier-Laplace transform of a Gaussian $u(x) = C e^{- \alpha x^2}$, where $C,\alpha>0$, must be an entire function (holomorphic everywhere) on $\bC$. Let us compute it. Assume for convenience that $u(x) = C e^{-x^2}$ where $C>0$ is chosen so that $$\int_{\bR} u(x) dx = 1.$$ Now 

\begin{align*} \mathcal{F}u (z) &=  \int_{\bR} C \exp ( -(x^2 + 2\pi i x z)) \\ &=  \int_{\bR} C\exp (- ((x+\pi i z)^2 + \pi^2 z^2)) \\ &=  e^{-\pi^2z^2} \int_{\bR} C \exp(-(x+\pi i z)^2) dx. \end{align*}

Since $\mathcal{F}u(z)$ is analytic on $\bC$ and the first factor never vanishes, we must have that the second factor is also analytic on $\bC$. That is, $$\int_{\bR} C \exp(-(x+\pi i z)^2) dx$$ is an analytic function on $\bC$. But we know that this function is constant for $z \in i \bR$ by translation invariance of the integral in the real domain. Thus by holomorphicity on $\bC$, this integral is constant over all $z \in \bC$ and so this integral is equal to $1$ (as we assumed it is at $z=0$). Thus we get that $$\mathcal{F}u(z) = e^{-\pi^2 z^2}$$ which is another Gaussian. Of course, it is well known $C = \frac{1}{\sqrt{\pi}}$.

\end{eg}

\subsection{Schwarz space of functions}

\begin{mydef} A function $f:\bR^d \to \bC$ is said to be \textit{rapidly decreasing} if for all polynomials $P(x_1, \dots, x_d) \in \bR[x_1, \ldots, x_d]$ we have that $$\lim_{x \to \infty} f(x)P(x) = 0.$$ We say that $f$ is a Schwarz function if $f$ and all partial derivatives of $\partial^{\alpha}f$, for $\alpha \in \bZ_{\geq 0}^d$ are rapidly decreasing. We let $\cS(\bR^d)$ denote the space of all Schwarz functions on $\bR^d$.

\end{mydef}

Note that to check rapidly decreasing it is enough to consider $P$ being a monomial.

\begin{lemma} Let $f:\bR^d \to \bC$ be a function that is bounded on every bounded set. Then the following are equivalent:

\begin{enumerate}
	\item $f$ is rapidly decreasing.
	\item For all integers $N>0$ exists a constant $C>0$ such that $$|f(x)| \leq C\| x \|^{-N} \quad\text{for all } \|x\| > 1.$$
	\item For all integers $N>0$ there exists a constant $C>0$ such that $$|f(x)| \leq C(\| x \| + 1)^{-N} \quad\text{for all } x \in \bR^d.$$
\end{enumerate}

\end{lemma}

\begin{proof} (i) $\implies$ (ii): If $f$ is rapidly then in particular $\|x\|^{2N}|f(x)| \to 0$ thus there exists large enough $R>1$ so that $$\|x\|^{N} \leq \|x\|^{2N}|f(x)| \leq 1$$ for all $|x| \geq R$. By assumption on the boundedness of $f$ on bounded sets, $|f(x)|/\|x\|^{N}|$ is bounded on the annulus $1\leq \|x\| \leq R$, so we just take $C>1$ to be larger than this maximum. (ii) $\implies$ (iii): Note that there is $R>0$ such that for $\|x \| \geq R$ we have $$(\|x \|+1)^{-N} \geq \| x \|^{-(N+1)} \geq \frac{1}{C}|f(x)|$$ for some $C>0$. One can choose a constant $C'>C$ so that we have the desired inequality $|f(x)| \leq C'(\| x \| + 1)^{-N}$ for $\|x \| \leq R$ by boundedness of $f$ on this ball. (iii) $\implies$ (i): Any monomial $x_{i_1} \ldots x_{i_N}$ for degree $N$ can be bounded by $(\|x\| + 1)^{-N}$. \end{proof}


\begin{prop} If $f,g \in \cS(\bR^d)$ then $f*g \in \cS(\bR^d)$. In particular, the convolution is everywhere defined. Moreover, for all $\alpha \in \bZ_{\geq 0}^d$ we have that $$\partial^{\alpha} (f * g) = (\partial^{\alpha}f * g).$$

\end{prop}

\begin{proof} Fix any polynomial $P:\bR^d \to \bR$ of degree $N$. Now observe that $$|P(x)(f*g)(x)| \leq |P(x)| \int_{\bR^d} |f(y)||g(x-y)|dy \leq C |P(x)| \int_{\bR^d} (1+\|y\|)^{-M} (1+\|x-y\|)^{-M}dy $$ for some constant $C>0$ where $M = \max\{N+1, d+2\}$. It is thus enough to show that as $x \to 0$ this integral behaves like $O(\|x\|^{-N-1})$. Observe that for each fixed $x \in \bR^d$ we have $\bR^d = A_1 \cup A_2$ where $$A_1 = \{y \in \bR^d ~|~ \|y - x\| \geq \frac{\|x\|}{2} \}$$ and $$A_2 = \{ y \in \bR^d ~|~ \|y \| \geq \frac{\|x\|}{2}\}.$$  Now observe that for $i=1$ we have that \begin{align*} \int_{A_i}(1+\|y\|)^{-M} (1+\|x-y\|)^{-M} &\leq \int_{A_i} (1+\|y\|)^{-M}\left(1+\frac{\|x\|}{2}\right)^{-M} \\ &=\left(1+\frac{\|x\|}{2}\right)^{-M} \int_{A_i} (1+\|y\|)^{-M} \\&= O(\|x\|^{-M}),\end{align*} which holds since $M\geq d+2$ and so the integral in the last line converges. The same inequality holds for $i=2$ as well by translation symmetry. Now since $M \geq N+1$ we have shown that $$|P(x)(f*g)(x)| = O(\|x\|^{-1}) \to 0.$$ Thus this completes the proof that $f*g$ is rapidly decreasing.

Now let $e_j$ be the $j$-th basis vector in $\bR^d$ and fix $x \in \bR^d$. For $t \in \bR \setminus \{0\}$ we consider $$\frac{(f*g)(x+te_j) - (f*g)(x)}{t} = \int_{\bR^d}f(y)\left(\frac{g(x-y+te_j) - g(x-y)}{t} \right) dy.$$ By the mean value theorem (only applies to $f,g$ real valued, but from bilinearity of convolution we can assume this) we know that $$\frac{g(x-y+te_j) - g(x-y)}{t} = (\partial_j g)(x-y + s_{y,t}e)$$ for some $s_{y,t} \in [0,t]$. But $\partial_j g$ is a rapidly decreasing continuous function, thus we obtain that it is uniformly continuous. This means that $$\frac{g(x-y+te_j) - g(x-y)}{t} \to (\partial_jg)(x-y) \quad \text{ uniformly for as } t \to 0.$$ As $f$ is integrable, this means that $$\int_{\bR^d}f(y)\left(\frac{g(x-y+te_j) - g(x-y)}{t} \right) dy \to \int_{\bR^d} f(y)(\partial_jg)(x-y) dy = (f*(\partial_jg))(x) \quad \text{as } t\to 0.$$

Thus we have shown that $$\partial_j (f*g)(x) = (f*\partial_g(x)).$$ Since $\partial_j g$ is also a Schwarz function, we can proceed inductively to show that $$\partial^{\alpha} (f * g) = (f *(\partial^{\alpha} g).$$ and this proves the stated inequality (convolution is commutative). Finally, this equality shows that all partial derivatives of $f*g$ are convolutions of Schwarz functions, and hence rapidly decreasing. This means that indeed $f*g \in \cS(\bR^d)$. \end{proof}

We define the operator $M_j$ on the set of functions $\bR^d \to \bC$ given by $$M_jf (x) = x_j f(x) \quad\text{for } x=(x_1, \ldots, x_d) \in \bR^d.$$ Clearly the $M_j$ preserve Schwarz space.

\begin{thm} If $\phi:\bR^d \to \bC$ is Schwarz, then so is its Fourier transform $\mathcal{F}\phi:\bR^d \to \bC$. Moreover, for $\phi \in \cS(\bR^d)$ we have that $$ \cF(\partial_j \phi) = 2\pi i M_j (\mathcal{F} \phi) $$ and $$\partial_j (\cF \phi) = -2\pi i \cF(M_j \phi).$$

\end{thm}

\begin{proof} First note that these equations will show that the Fourier transform is a Schwarz function as follows. If $\alpha = (\alpha_1, \ldots, \alpha_d) \in \bZ_{\geq 0}^d$ is an index then by induction and the first equation we get that $$\mathcal{F}(\partial^{\alpha}\phi)(\omega) = (2\pi i)^{\|\alpha\|_1} \omega^{\alpha} (\mathcal{F}\phi)(\omega).$$ But by the Riemann-Lebesgue lemma, we have that the right hand side converges to $0$ and $\omega \to \infty$. Thus we have shown that $$\lim_{\omega \to \infty} |P(\omega)| (\mathcal{F}(\omega)) = 0$$ for all polynomials $P$. Thus the Fourier transform will be shown to be rapidly decreasing by the first identity. The second identity then shows that every element in the space $\mathcal{F}(\cS(\bR^d))$ has a continuous partial derivative and that this space is invariant under partial differentiation, which shows that the Fourier transform of a Schwarz function is smooth. Thus this will show that the Fourier transform of a Schwarz function is Schwarz.

The first identity is an easy application of inegration by parts as follows:

\begin{align*} \cF(\partial_j \phi) (\omega) &= \int_{\bR^d} \partial_j\phi(x) e^{-2\pi i \langle x, \omega \rangle} dx 
\\ &= -\int_{\bR^d} \phi(x) \partial_j (e^{-2\pi i \langle x, \omega \rangle}) dx
\\ &= 2\pi i \omega_j \int_{\bR^d} \mathcal{F}(\phi) (\omega)
\\& = 2\pi i M_j (\mathcal{F}(\phi)) (\omega).\end{align*}

For the second identity, we apply differentiation under the integral sign (Proposition~\ref{prop: diff under int}) as follows:

\begin{align*} \partial_j (\cF \phi)(\omega)  &= \int_{\bR^d} -2\pi i x_j \phi(x) e^{-2\pi i \langle x, \omega \rangle} dx \\
&= -2\pi i \mathcal{F}(M_j\phi)(\omega) \end{align*}

where the differentation under the integral sign is justified since $$|-2\pi i x_j \phi(x) e^{-2\pi i \langle x, \omega \rangle}| = 2\pi  |x_j \phi(x)|$$ and as $\phi$ is rapidly decreasing and measurable, we have that $x \mapsto x_j \phi(x)$ is integrable. Thus the integrand is bounded by an integrable function that is independent of $\omega$. \end{proof}


\subsection{Fourier inversion of Schwarz functions}

\begin{thm}[Multiplication formula] If $\phi, \psi \in S(\bR^d)$ then $$\int_{\bR^d} \phi(x) \cdot \cF \psi(x) d(x) = \int_{\bR^d} \cF \phi (x) \cdot \psi(x) dx.$$

\end{thm}

\begin{proof} We may apply Fubini's theorem to show that the left hand side is equal to $$\int_{\bR^d} \phi(x) \left(\int_{\bR^d} \psi(y) e^{-2\pi i \langle x, y \rangle } dy \right) dx = \int_{\bR^d \times \bR^d} \phi(x) \psi(y) e^{-2\pi i \langle x, y \rangle } dx dy  $$ where the use of Fubini's theorem is justified as $|\phi(x)\phi(y)|$ is in $L^1(\bR^d \times \bR^d)$. Now this expression is symmetric in $\phi$ and $\psi$. \end{proof}

\begin{thm}[Fourier inversion] For $\phi \in S(\bR^d)$ we have that $$\phi(x) = \int_{\bR^d} \mathcal{F}\phi (\omega) \cdot e^{2\pi i \langle x , \omega \rangle } d\omega.$$

\end{thm}

\begin{proof} Let $$K(x) = C e^{-\|x\|^2}$$ where $C>0$ is chosen so that $$\int_{\bR^d} K(x) dx = 1.$$ We know from Example~\ref{eg: FT of Gaussian} that $$\mathcal{F}K(\omega) = e^{-\pi^2 \|\omega\|^2}$$ is also a Gaussian. Now for $\alpha>0$ let $$K_{\alpha}(x) = K(\alpha x).$$ Thus we know that $$\mathcal{F}(K_{\alpha}) (\omega) = \alpha^{-d} \mathcal{F}(K) (\alpha^{-1} \omega) = \alpha^{-d} e^{-\pi^2 \|\alpha^{-1} \omega\|^2}.$$ Now we apply the multiplication formula to $\phi$ and $K_{\alpha}$ to get $$ \int_{\bR^d} \phi(x) \cdot \cF K_{\alpha}(x) d(x) = \int_{\bR^d} \cF \phi (x) \cdot K_{\alpha}(x) dx.$$ Now as $\mathcal{F}\phi$ is Schwarz and thus integrable, we can apply the dominated converge theorem to show that as $\alpha \to 0$, the right hand side converges to $$\int_{\bR^d} \mathcal{F}\phi(\omega) d\omega.$$ On the other hand, the left hand side converges to $\phi(0)$ since for all $\alpha>0$ we have $$\int_{\bR^d} K_{\alpha}(x) dx = 1$$ but for all $\epsilon>0$ we have that $$\int_{|x|>\epsilon} K_{\alpha}(x) dx \to 1 \quad\text{ as } \alpha \to 0 .$$ Thus we have shown that $$\phi(0) = \int_{\bR^d} \mathcal{F}\phi(x) d\omega,$$ which is the $x = 0$ case. To derive the general case, we may consider the Schwarz function $\phi_y (x) = \phi(y+x)$ and apply the already proven $x = 0$ case to obtain that $$\phi(y) = \phi_y(0) = \int_{\bR^d} \mathcal{F}\phi_y(\omega) d\omega.$$ But $$(\mathcal{F}\phi_y) (\omega) = \int_{\bR^d} \phi(y+x) e^{-2\pi i \langle x , \omega \rangle} dx =  \int_{\bR^d} \phi(x) e^{-2\pi i \langle x - y , \omega \rangle} dx = (\mathcal{F}\phi)(\omega) e^{2\pi i y\omega},$$ as desired.

\end{proof}

\begin{eg}[Calculation of the Gaussian integral via Fourier Analysis] Continuing from Example~\ref{eg: FT of Gaussian} we have shown that if $$u(x) = C e^{-x^2}$$ where the constant $C$ is chosen so that $$\int_{\bR} u(x) dx = 1$$ then $$\mathcal{F}u(\omega) =  e^{-\pi^2 \omega^2}.$$ Applying the Fourier inversion formula, we get that $$C = u(0) = \int_{\bR} e^{-\pi^2 \omega^2} d\omega = \pi^{-1} \int_{\bR} e^{-x^2} dx = \pi^{-1}C^{-1}. $$ Thus $C = \frac{1}{\sqrt{\pi}}$, that is $$\int_{\bR} e^{-x^2} dx = \sqrt{\pi}.$$ Note that there is no circular logic here as although we needed the Fourier transform of a Gaussian, we did not need the exact value of $C$ in any of our proofs of Fourier inversion. \end{eg}

\begin{corol} The Fourier Transform is a bijection $\mathcal{F}:\cS(\bR^d) \to \cS(\bR^d)$ with inverse given by $$\mathcal{F}^{-1} = \mathcal{F} \circ S$$ where $S\phi (x) = \phi(-x)$.

\end{corol}

\begin{proof} The Fourier Inversion formula gives that $$\phi(x) = \int_{\bR^d} (\mathcal{F}\phi) (\omega) e^{2\pi  i \langle \omega, x \rangle} d\omega = \int_{\bR^d} (S(\mathcal{F}\phi))(\omega) e^{-2\pi i \langle\omega, x \rangle} d \omega = \mathcal{F}(S\mathcal{F}(\phi))(x).$$ This shows that $$\mathcal{F} \circ S \circ \mathcal{F} = \operatorname{Id}_{\cS(\bR^d)}.$$ Thus if we let $\mathcal{G} = S \circ \mathcal{F}$ and $\mathcal{G}' = \mathcal{F} \circ S$ then we see that $\cG$ is a right inverse and $\cG'$ is a left inverse of $\mathcal{F}$. But we must have $\cG = \cG'$ by simple algebra (i.e., we have $\cF \cG = 1$ and $\cG' \cF = 1$, now multiplying by $\cG$ on both sides of of the second equation we get $\cG' \cF \cG = \cG$ and then using the first equation we get $\cG' = \cG$). \end{proof}

\section{Tempered Distributions and their Fourier Transform}

\subsection{Topology on Schwarz space}

\begin{mydef} We say that $\phi_1, \phi_2, \ldots \in \cS(\bR^d)$ converge in $\cS(\bR^d)$ to some $\phi \in \cS(\bR^d)$ if for all all indices $\alpha, \beta \in \bZ_{\geq 0}^d$ we have that $$x^{\beta}\partial^{\alpha}\phi_i \to x^{\beta}\partial^{\alpha}\phi \quad \text{uniformly on } \bR^d.$$

\end{mydef}

We observe that if $\phi_i \to \phi$ in $D(\bR^d)$ then they also converge in $\cS(\bR^d)$.  Thus we have a continuous embedding (preservers limits) $$D(\bR^d) \subset \cS(\bR^d).$$

However if one considers the functions $\phi_1, \phi_2, \ldots \in D(\bR^d)$ given by $\phi_n (x) =\phi_1 (x-n)$ (a gliding hump) then although in $C^{\infty}(\bR^d)$ this sequence of functions converges to $0$ (i.e., all its partial derivatatives converge to $0$ uniformly on compact sets) but not in $\cS(\bR^d)$ as the convergence is not uniform on all of $\bR^d$.

\begin{eg}[Multiplcation by $x^{\beta}$ is not reduntant] \label{eg: schwarz convergence} Let $\phi \in D(\bR)$ be any compactly supported non-zero smooth function. Let $\phi_n = 2^{-n} \phi(x-n)$. Say that support of $\phi$ is in $[0,1]$, thus the support of $\phi_n$ is $[n,n+1]$. Then $\phi_n \to 0$ in $\cS(\bR)$, which we justify as follows. Observe that $$\sup_{x \in \bR^d}|x^{\beta} \partial^{\alpha}\phi_n(x)| \leq 2^{-n}n^{|\beta|} \sup_{x \in [0,1]} | \partial^{\alpha}\phi(x)|$$ and this converges to $0$ uniformly since exponentials dominate polynomials. On the other hand, if we define $\psi_n = \frac{1}{n} \phi(x-n)$ then $\psi_n$ does not converge to $0$ in $\cS(\bR)$, even though all partial derivatives converge uniformly on $\bR$ to $0$. This is because $$\sup_{x \in \bR^d} | x^2 \phi_n(x) | \geq n^2 n^{-1} \sup_{x \in \bR^d} |\phi(x)| = n \sup_{x \in \bR^d} |\phi(x)|$$ which does not converge to $0$ as the lower bound is linear in $n$.

\end{eg}

\begin{mydef}[Norms on Schwartz space] It will be convenient to define for $\phi \in \cS(\bR^d)$ the norm $$\| \phi \|_{\cS(k,N)} = \sup_{|\alpha|\leq k, |\beta|\leq N, x \in \bR^d} |x^{\beta} \partial^{\alpha} \phi| .$$

\end{mydef}

Thus we have that $\phi_i \to \phi$ in $\cS(\bR^d)$ if and only if $\| \phi_i - \phi\|_{\cS(k,N)} \to 0$ for all non-negative integers $k,N$.

\begin{prop}\label{prop: Schwarz function is limit of compactly supported} If $\phi \in \cS(\bR^d)$ then there are $\phi_i \in \cS(\bR^d)$ that are compactly supported and $\phi_i \to \phi$ in $\cS(\bR^d)$.

\end{prop} 

\begin{proof} Let $\psi:\bR^d \to \bR$ be a smooth function with compact support such that $\psi(x) = 1$ for all $\|x \| \leq 1$. Now let $$\phi_n(x) = \psi(x/n) \phi(x).$$ Clearly $\phi_n \in \cS(\bR^d)$ is compactly supported. To show that $\phi_n \to \phi$ in $\cS(\bR^d)$, we will need to estimate the norms above as follows. First use the product rule to write $$x^{\beta} \partial^{\alpha}\left( (\psi(x/n) - 1) \phi(x) \right) =  x^{\beta} (\psi(x/n) - 1) \partial^{\alpha} \phi(x)  + \sum_{0 \neq \gamma \leq \alpha} O(n^{-|\gamma|}) x^{\beta}\partial^{\alpha - \gamma} \phi(x) $$ where the implicit $O$ constant depends on $\gamma$ (and thus can be chosen so it depends on $\alpha$ only). Thus we now wish to show that both terms convergence uniformly as $n \to \infty$. The first term is bounded by $$\|\psi\|_{\infty} \sup_{\|x\| > n} x^{\beta}  |\partial^{\alpha} \phi(x)|$$ and this converges to $0$ uniformly as $n \to \infty$ by definition of Schwarz function. The second term clearly converges to $0$ as $x^{\beta} \partial^{\alpha - \gamma}\phi(x)$ is bounded on $\bR^d$. \end{proof}

We say that an operator $\cS(\bR^d) \to \cS(\bR^d)$ is continuous if it preserves limits in $\cS(\bR^d)$.

\begin{lemma}\label{lemma: diff and poly continuous} The operators $\phi \mapsto \partial^{\alpha}\phi$ and $\phi \mapsto x^{\beta}\phi$ are continuous functions on $\cS(\bR^d)$.

\end{lemma}

\begin{proof} The claim about partial derivatives is obvious. For the second claim, assume that $\phi_n \to 0$ in $\cS(\bR^d)$. Then $$x^{\beta'} \partial^{\alpha} (x^{\beta} \phi_n(x))$$ is a finite sum of terms of the form $P(x)\partial^{\gamma}\phi_n(x)$ for some polynomials $P$ and indices $\gamma$. Thus by definition of Schwarz functions, we have that such terms converge to $0$ in $\cS(\bR^d)$. \end{proof}

\begin{prop} The Fourier transform $\cF:\cS(\bR^d) \to \cS(\bR^d)$ is continuous. So is its inverse.

\end{prop}

\begin{proof} Suppose that $\phi_n \to 0$ in $\cS(\bR^d)$. We first show that $$\| \cF(\phi_n)\|_{\infty} \to 0.$$ To see this, note that $$|\cF(\phi_n) (\omega)| \leq \int_{\bR^d} |\phi_n(x)| dx$$ so it is enough to show that this upper bound, which is independent of $\omega$, converges to $0$. Letting $P(x) = (1 + \|x\|^2)^{d+1}$ we have that $$\int_{\bR^d}|\phi_n(x)| dx = \int_{\bR^d} \frac{1}{P(x)} |\phi_n(x)P(x)| dx \leq \sup_{x \in \bR^d} |\phi_n(x)P(x)|  \int_{\bR^d} \frac{1}{P(x)} dx.$$ On the other hand $$\sup_{x \in \bR^d} |\phi_n(x)P(x)| \to 0 \quad\text{uniformly for } x \in \bR^d.$$ Thus we have shown that $\|\cF(\phi_n)\|_{\infty} \to 0$ whenever $\phi_n \to 0$ in $\cS(\bR^d)$. It now remains to show that $$\lim_{n \to \infty} \|x^{\beta} \partial^{\alpha} \cF(\phi_n)\|_{\infty} = 0.$$ But $$x^{\beta} \partial^{\alpha} \cF(\phi_n) = (2\pi i)^{|\alpha|}(-2\pi i)^{-|\beta|} \cF(\partial^{\beta} (x^{\alpha} \phi_n)).$$ By Lemma~\ref{lemma: diff and poly continuous} $\partial^{\beta} x^{\beta} \phi_n \to 0$ in $\cS(\bR^d)$ and so by what we have already shown (the $\alpha = \beta = 0$ case) we see that indeed $$\|\cF(\partial^{\beta} (x^{\alpha} \phi_n))\|_{\infty} \to 0.$$

Thus the Fourier transform is continuous. Moreover the inverse of the fourier transform is $\mathcal{F}^{-1} = \mathcal{F} \circ S$ where $S$ is clearly continuous in $\cS(\bR^d)$. Thus the $\mathcal{F}^{-1}$ is continuous. \end{proof}

\subsection{Tempered distributions}

\begin{mydef} A \textit{tempered distribution} is a linear functional $u:\cS(\bR^d) \to \bC$ that is continuous in the sense that if $\phi_n \to \phi$ in $\cS(\bR^d)$ then $u(\phi_n) \to u(\phi)$. We let $\mathcal{S}'(\bR^d)$ denote the space of tempered distributions. We say that a sequence of tempered distributions $u_1,u_2,\ldots$ converges to a tempered distribution $u$ \textit{in $\cS'(\bR^d)$} if for all $\phi \in \cS(\bR^d)$ we have that $u_j(\phi) \to u(\phi)$.

\end{mydef}

We now give some examples and non-examples.

\begin{prop} ~
\begin{itemize}
	\item Every tempered distribution $u \in \mathcal{S}'(\bR^d)$ restricts to a distribution in $D'(\bR^d)$. This restriction mapping is injective and continuous.
	\item Every compactly supported distribution $u \in \mathcal{E}'(\bR^d)$ restricts to a tempered distribution. This restriction mapping is injective and continuous.
\end{itemize}

\end{prop}

\begin{proof} 

First suppose that $u \in \mathcal{S}'(\bR^d)$ and $\phi_n \to \phi$ in $D(\bR^d)$. This means there is a compact set $K$ containing the support of all $\phi_n$ and $\phi$ and for each index $\alpha$ we have $ \partial^{\alpha} \phi_n \to \partial^{\alpha} \phi$ uniformly on $K$ and thus uniformly on $\bR^d$. So we have $\phi_n \to \phi$ in $\cS(\bR^d)$ and so indeed $u(\phi_n) \to u(\phi)$. Thus the restriction of $u$ to $D(\bR^d)$ gives a well defined continuous distribution $u \in D'(\bR^d)$. Clearly this restriction mapping is continuous since the definition of convergence of the distributions is the same. To show injectivity, note that by Proposition~\ref{prop: Schwarz function is limit of compactly supported} any tempered distribution $u$ is determined by its values on comapctly supported smooth functions. Thus if $u_1,u_2 \in \mathcal{S}'(\bR^d)$ restrict to the same element in $D'(\bR^d)$, then they must be equal.

Now suppose $u \in \mathcal{E}'(\bR^d)$ and $\phi_n \to \phi$ in $\cS(\bR^d)$. Then in particular we may view $\phi_n, \phi \in C^{\infty}(\bR^d)$, thus $u$ restricts to a well defined linear map functional on $\cS(\bR^d)$. Now $\phi_n \to \phi$ uniformly on $\bR^d$ and so it clearly converges in $C^{\infty}(\bR^d)$ (which is uniform convergence on compact subsets). Continuity is clear as the definitions of convergence coincide. To show injectivity, suppose $u_1,u_2 \in \mathcal{E}'(\bR^d)$ restrict to the same element of $\cS'(\bR^d)$. Thus $u_1,u_2$ restrict to the same element of $D'(\bR^d)$. By Lemma~\ref{lemma: E' embeds in D'} that this means that $u_1 = u_2$ are the same element of $\mathcal{E}'(\bR^d)$.

\end{proof}

In summary, this means that we have natural inclusions of distributions $$\mathcal{E}'(\bR^d) \hookrightarrow \cS'(\bR^d) \hookrightarrow D'(\bR^d).$$ which are continuous in the sense that they preserve limits (i.e., if $u_j \to u$ then it does so when embedded in the larger space). We now show that these inclusions are proper.

\begin{eg}[A non-tempered distribution] Consider the distribution $u \in D'(\bR)$ given by $$u(\phi) = \int e^x \phi(x) dx.$$ We claim that there is no tempered distribution that restricts to this distribution. Suppose there was such a distribution $u$. Now choose a compactly supported non-negative and non-zero smooth function $\phi \in D(\bR)$. Let us assume it is supported on $[0,1]$. We already know that $$\phi_n(x) = e^{-n/2}\phi(x-n)$$ is a sequence of compactly supported Schwarz functions that converge to $0$ in $\cS(\bR^d)$ (see Example~\ref{eg: schwarz convergence}). However $$u(\phi_n) = \int_{n}^{n+1} e^{x - n/2} \phi(x-n) \geq e^{\frac{n}{2}} \int_0^1 \phi(x) \to \infty \neq 0 = u(0),$$ thus $u$ is not continuous in $\cS(\bR^d)$.

\end{eg}

We now demonstrate many tempered distributions that are not compactly supported.

\appendix

\section{Differentiation under the integral sign}

\begin{prop} \label{prop: diff under int} Let $X$ be a measurable space with a finite signed measure (a different of finite positive measures) $\mu$ on $X$. Suppose $U \subset \bR$ is open and $K:X \times U \to \bC$ is measurable such that

\begin{enumerate}
	\item For each $x \in X$, the maps $K_x:U \to \bC$ given by $K_x(t) = K(x,t)$, are differentiable in on $U$. 
	\item There exists a $\mu$-integrable function $g:X \to [0,\infty)$ (i.e., $\int_X g(x) d\mu(x) < \infty$) such that $|K_x'(t)| \leq g(x)$ for all $t \in U, x \in X$.
	\item For each fixed $t \in U$, the map $x \mapsto K(x,t)$ is $\mu$-integrable.
\end{enumerate}

Then the map $F:U \to \bC$ given by $$F(t) = \int_{X} K(x,t) d\mu(x)$$ defines a differentiable function with derivative equal to $$F'(t) = \int_X K_x'(t) d\mu(x) = \int_X \frac{\partial}{\partial s}|_{s = t} K(x,s) d\mu(x)$$

\end{prop}

\begin{proof} By considering the real and imaginary parts of $K(x,t)$, we can reduce to the case where $K$ is a real valued function. Indeed, if $K(x,t) = K_1(x,t) + iK_2(x,t)$ where $K_1,K_2$ are real valued then $K_1,K_2$ are clearly differentiable in $t$ and $|K_1(x,t)|, |K_2(x,t)|  \leq |K(x,t)|$ thus the real and imaginary parts are integrable. Likewise, the derivatives of the real and imaginary parts are at most $|K'_x(t)|$ and so are at most $g$. So all the assumptions are preserved for the real and imaginary parts.

Now to $t \in U$ fixed and sufficiently small $h$ we have that $$\frac{F(t+h) - F(t)}{h} = \int_X \frac{K_x(t+h) - K_x(t)}{h} d\mu(x).$$

We wish to show that as $h \to 0$, both the left hand side and right hand side converge to the same limit, which will complete the proof. To justifty this we use Lebesgue's Dominated Convergence theorem, which may be justified since by the mean value theorem, there exists for each $x \in X$ and $h$ sufficiently small some $t_{h,x} \in [t,t+h]$ such that $$\frac{K_x(t+h) - K_x(t)}{h} = K_x'(t_{h,x}).$$ But by assumption $|K_x'(t_{h,x})| \leq g(x)$ and so the integrand is bounded, for each such $h$, by the integrable function $g$. Thus by Lebesgue's dominated convergence theorem, we have the desired limiting behaviour. \end{proof}


\begin{thebibliography}{99}

\bibitem{DK} Duistermaat, J. J.; Kolk, J. A. C. \emph{Distributions. Theory and applications.} Translated from the Dutch by J. P. van Braam Houckgeest. Cornerstones. Birkhuser Boston, Inc., Boston, MA, 2010. xvi+445 pp. ISBN: 978-0-8176-4672-1 

\end{thebibliography} 



\end{document}